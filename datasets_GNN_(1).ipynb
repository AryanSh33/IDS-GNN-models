{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "j8SmmegQ1i3X",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j8SmmegQ1i3X",
        "outputId": "e394e5db-8f88-42dd-fd40-5377f8ca91c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.7.0-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/63.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.13.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2025.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.2.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.6.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.22.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch-geometric) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2025.11.12)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp->torch-geometric) (4.15.0)\n",
            "Downloading torch_geometric-2.7.0-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.7.0\n"
          ]
        }
      ],
      "source": [
        "!pip install torch-geometric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "e539ff63",
      "metadata": {
        "cellView": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e539ff63",
        "outputId": "78597213-71c9-49f5-e401-4d0cce5e11f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting imblearn\n",
            "  Downloading imblearn-0.0-py2.py3-none-any.whl.metadata (355 bytes)\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.12/dist-packages (from imblearn) (0.14.0)\n",
            "Requirement already satisfied: numpy<3,>=1.25.2 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn->imblearn) (2.0.2)\n",
            "Requirement already satisfied: scipy<2,>=1.11.4 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn->imblearn) (1.16.3)\n",
            "Requirement already satisfied: scikit-learn<2,>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn->imblearn) (1.6.1)\n",
            "Requirement already satisfied: joblib<2,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn->imblearn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn->imblearn) (3.6.0)\n",
            "Downloading imblearn-0.0-py2.py3-none-any.whl (1.9 kB)\n",
            "Installing collected packages: imblearn\n",
            "Successfully installed imblearn-0.0\n"
          ]
        }
      ],
      "source": [
        "# @title Default title text\n",
        "!pip install imblearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "70ed5e1c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70ed5e1c",
        "outputId": "6faf59ae-553f-46cb-e832-4766a2e6e276"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'unsw-nb15' dataset.\n",
            "Path to dataset files: /kaggle/input/unsw-nb15\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"mrwellsdavid/unsw-nb15\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "eb8726d4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eb8726d4",
        "outputId": "fad4175f-a6ba-42fc-cad5-28ef51842504"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/chethuhn/network-intrusion-dataset?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 230M/230M [00:02<00:00, 103MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/chethuhn/network-intrusion-dataset/versions/1\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"chethuhn/network-intrusion-dataset\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "8164bac8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8164bac8",
        "outputId": "a55a80d2-8fc7-4369-dd7f-d8b71b6648fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/kaggle/input/unsw-nb15/UNSW_NB15_training-set.csv\n"
          ]
        }
      ],
      "source": [
        "ls /kaggle/input/unsw-nb15/UNSW_NB15_training-set.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "8e0ba766",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8e0ba766",
        "outputId": "2b5563f3-51bc-4775-ae1d-4d7f0cdb442f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ls: cannot access '/kaggle/input/network-intrusion-dataset': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "ls /kaggle/input/network-intrusion-dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "5ddc0ad8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ddc0ad8",
        "outputId": "5c3d0a23-ff13-4562-bcfd-081feeee5a14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columns: ['id', 'dur', 'proto', 'service', 'state', 'spkts', 'dpkts', 'sbytes', 'dbytes', 'rate', 'sttl', 'dttl', 'sload', 'dload', 'sloss', 'dloss', 'sinpkt', 'dinpkt', 'sjit', 'djit']\n",
            "Shape: (82332, 45)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the official training split\n",
        "unsw_df = pd.read_csv(r\"/kaggle/input/unsw-nb15/UNSW_NB15_training-set.csv\")\n",
        "\n",
        "print(\"Columns:\", list(unsw_df.columns)[:20])\n",
        "print(\"Shape:\", unsw_df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "aef53a28",
      "metadata": {
        "id": "aef53a28"
      },
      "outputs": [],
      "source": [
        "unsw = unsw_df[['dur', 'proto', 'service', 'state',\n",
        "                'spkts', 'dpkts', 'sbytes', 'dbytes',\n",
        "                'rate', 'sttl', 'dttl', 'sload', 'dload',\n",
        "                'sinpkt', 'dinpkt', 'sjit', 'djit',\n",
        "                'attack_cat', 'label']].copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "4f7579b1",
      "metadata": {
        "id": "4f7579b1"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Encode protocol, service, state, attack_cat\n",
        "for col in ['proto', 'service', 'state', 'attack_cat']:\n",
        "    unsw[col] = LabelEncoder().fit_transform(unsw[col].astype(str))\n",
        "\n",
        "# Normalize numeric columns (optional for neural models)\n",
        "num_cols = ['dur', 'spkts', 'dpkts', 'sbytes', 'dbytes',\n",
        "            'rate', 'sttl', 'dttl', 'sload', 'dload',\n",
        "            'sinpkt', 'dinpkt', 'sjit', 'djit']\n",
        "unsw[num_cols] = unsw[num_cols].apply(lambda x: (x - x.min()) / (x.max() - x.min()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "bcc94185",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcc94185",
        "outputId": "c938da41-c50a-4503-f8b2-0196d636b95b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2830743, 79)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import glob\n",
        "\n",
        "# Updated path to the downloaded CIC-IDS dataset\n",
        "path = r\"/root/.cache/kagglehub/datasets/chethuhn/network-intrusion-dataset/versions/1\"\n",
        "all_files = glob.glob(path + \"/*.csv\")\n",
        "\n",
        "cic_dfs = []\n",
        "for f in all_files:\n",
        "    df = pd.read_csv(f)\n",
        "    cic_dfs.append(df)\n",
        "\n",
        "cic = pd.concat(cic_dfs, ignore_index=True)\n",
        "print(cic.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "e028e3f9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e028e3f9",
        "outputId": "71bf31d6-ae21-47f6-b2d5-72b67907035c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index([' Destination Port', ' Flow Duration', ' Total Fwd Packets',\n",
              "       ' Total Backward Packets', 'Total Length of Fwd Packets',\n",
              "       ' Total Length of Bwd Packets', ' Fwd Packet Length Max',\n",
              "       ' Fwd Packet Length Min', ' Fwd Packet Length Mean',\n",
              "       ' Fwd Packet Length Std', 'Bwd Packet Length Max',\n",
              "       ' Bwd Packet Length Min', ' Bwd Packet Length Mean',\n",
              "       ' Bwd Packet Length Std', 'Flow Bytes/s', ' Flow Packets/s',\n",
              "       ' Flow IAT Mean', ' Flow IAT Std', ' Flow IAT Max', ' Flow IAT Min',\n",
              "       'Fwd IAT Total', ' Fwd IAT Mean', ' Fwd IAT Std', ' Fwd IAT Max',\n",
              "       ' Fwd IAT Min', 'Bwd IAT Total', ' Bwd IAT Mean', ' Bwd IAT Std',\n",
              "       ' Bwd IAT Max', ' Bwd IAT Min', 'Fwd PSH Flags', ' Bwd PSH Flags',\n",
              "       ' Fwd URG Flags', ' Bwd URG Flags', ' Fwd Header Length',\n",
              "       ' Bwd Header Length', 'Fwd Packets/s', ' Bwd Packets/s',\n",
              "       ' Min Packet Length', ' Max Packet Length', ' Packet Length Mean',\n",
              "       ' Packet Length Std', ' Packet Length Variance', 'FIN Flag Count',\n",
              "       ' SYN Flag Count', ' RST Flag Count', ' PSH Flag Count',\n",
              "       ' ACK Flag Count', ' URG Flag Count', ' CWE Flag Count',\n",
              "       ' ECE Flag Count', ' Down/Up Ratio', ' Average Packet Size',\n",
              "       ' Avg Fwd Segment Size', ' Avg Bwd Segment Size',\n",
              "       ' Fwd Header Length.1', 'Fwd Avg Bytes/Bulk', ' Fwd Avg Packets/Bulk',\n",
              "       ' Fwd Avg Bulk Rate', ' Bwd Avg Bytes/Bulk', ' Bwd Avg Packets/Bulk',\n",
              "       'Bwd Avg Bulk Rate', 'Subflow Fwd Packets', ' Subflow Fwd Bytes',\n",
              "       ' Subflow Bwd Packets', ' Subflow Bwd Bytes', 'Init_Win_bytes_forward',\n",
              "       ' Init_Win_bytes_backward', ' act_data_pkt_fwd',\n",
              "       ' min_seg_size_forward', 'Active Mean', ' Active Std', ' Active Max',\n",
              "       ' Active Min', 'Idle Mean', ' Idle Std', ' Idle Max', ' Idle Min',\n",
              "       ' Label'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "cic.columns\n",
        "# Typical relevant features:\n",
        "# ['Flow Duration', 'Total Fwd Packets', 'Total Backward Packets',\n",
        "#  'Total Length of Fwd Packets', 'Total Length of Bwd Packets', 'Protocol', 'Label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "8f54191e",
      "metadata": {
        "id": "8f54191e"
      },
      "outputs": [],
      "source": [
        "# Strip spaces from columns\n",
        "cic.columns = cic.columns.str.strip()\n",
        "\n",
        "# Columns to keep\n",
        "keep_cols = ['Flow Duration', 'Total Fwd Packets', 'Total Backward Packets',\n",
        "             'Total Length of Fwd Packets', 'Total Length of Bwd Packets',\n",
        "             'Label']\n",
        "\n",
        "# Keep only required columns\n",
        "combined = cic[keep_cols].copy()\n",
        "\n",
        "# Rename columns to match UNSW style (optional)\n",
        "combined.rename(columns={\n",
        "    'Flow Duration':'dur',\n",
        "    'Total Fwd Packets':'spkts',\n",
        "    'Total Backward Packets':'dpkts',\n",
        "    'Total Length of Fwd Packets':'sbytes',\n",
        "    'Total Length of Bwd Packets':'dbytes',\n",
        "    'Protocol':'proto',\n",
        "    'Label':'attack_cat'\n",
        "}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "e0103f8e",
      "metadata": {
        "id": "e0103f8e"
      },
      "outputs": [],
      "source": [
        "# Attack label encoding (0=normal, 1=attack)\n",
        "combined['attack_cat'] = combined['attack_cat'].apply(lambda x: 0 if str(x).lower()=='benign' else 1)\n",
        "\n",
        "# Normalize numeric features\n",
        "num_cols = ['dur','spkts','dpkts','sbytes','dbytes']\n",
        "combined[num_cols] = combined[num_cols].apply(lambda x: (x - x.min()) / (x.max() - x.min()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "43522b3b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43522b3b",
        "outputId": "efcf1282-f3dd-4efb-dcd7-f460bfb14627"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "UNSW columns: ['id', 'dur', 'proto', 'service', 'state', 'spkts', 'dpkts', 'sbytes', 'dbytes', 'rate', 'sttl', 'dttl', 'sload', 'dload', 'sloss', 'dloss', 'sinpkt', 'dinpkt', 'sjit', 'djit', 'swin', 'stcpb', 'dtcpb', 'dwin', 'tcprtt', 'synack', 'ackdat', 'smean', 'dmean', 'trans_depth', 'response_body_len', 'ct_srv_src', 'ct_state_ttl', 'ct_dst_ltm', 'ct_src_dport_ltm', 'ct_dst_sport_ltm', 'ct_dst_src_ltm', 'is_ftp_login', 'ct_ftp_cmd', 'ct_flw_http_mthd', 'ct_src_ltm', 'ct_srv_dst', 'is_sm_ips_ports', 'attack_cat', 'label']\n",
            "CIC columns: ['dur', 'spkts', 'dpkts', 'sbytes', 'dbytes', 'attack_cat']\n"
          ]
        }
      ],
      "source": [
        "# Example columns after preprocessing\n",
        "# ['dur', 'spkts', 'dpkts', 'sbytes', 'dbytes', 'attack_cat']\n",
        "\n",
        "unsw_cols = unsw_df.columns.tolist()\n",
        "cic_cols = combined.columns.tolist()\n",
        "\n",
        "print(\"UNSW columns:\", unsw_cols)\n",
        "print(\"CIC columns:\", cic_cols)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "4f6ab852",
      "metadata": {
        "id": "4f6ab852"
      },
      "outputs": [],
      "source": [
        "common_cols = ['dur','spkts','dpkts','sbytes','dbytes','attack_cat']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "74c98a70",
      "metadata": {
        "id": "74c98a70"
      },
      "outputs": [],
      "source": [
        "unsw_common = unsw_df[common_cols].copy()\n",
        "cic_common = combined[common_cols].copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "808e183d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "808e183d",
        "outputId": "a5755632-46e2-4103-d770-8fe8f0d4dae9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combined dataset shape: (2913075, 6)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "combined_df = pd.concat([unsw_common, cic_common], ignore_index=True)\n",
        "print(\"Combined dataset shape:\", combined_df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "7f8b1df6",
      "metadata": {
        "id": "7f8b1df6"
      },
      "outputs": [],
      "source": [
        "combined_df = combined_df.sample(frac=1, random_state=42).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "57cb244e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57cb244e",
        "outputId": "9103bd0d-2799-4fa8-fbc0-225612e9f496"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack_cat\n",
            "0                 2273097\n",
            "1                  557646\n",
            "Normal              37000\n",
            "Generic             18871\n",
            "Exploits            11132\n",
            "Fuzzers              6062\n",
            "DoS                  4089\n",
            "Reconnaissance       3496\n",
            "Analysis              677\n",
            "Backdoor              583\n",
            "Shellcode             378\n",
            "Worms                  44\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(combined_df['attack_cat'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "ac6183cb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ac6183cb",
        "outputId": "0ae1393a-bb16-4a63-d171-6d197bd454d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Binary label distribution:\n",
            "label\n",
            "0    2310097\n",
            "1     602978\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = combined_df.copy()\n",
        "\n",
        "# Keep original attack_cat for reference\n",
        "df['orig_attack_cat'] = df['attack_cat']\n",
        "\n",
        "# Function to convert mixed labels to binary\n",
        "def to_binary_label(x):\n",
        "    if pd.isna(x):\n",
        "        return 1  # treat unknown as attack\n",
        "    s = str(x).strip().lower()\n",
        "    if s in ('0', 'normal', 'benign'):\n",
        "        return 0\n",
        "    else:\n",
        "        return 1\n",
        "\n",
        "# Create binary label column\n",
        "df['label'] = df['attack_cat'].apply(to_binary_label)\n",
        "\n",
        "# Verify\n",
        "print(\"Binary label distribution:\")\n",
        "print(df['label'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "8a475ed3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8a475ed3",
        "outputId": "b391b2fc-70eb-41e3-9499-af65881c5c5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of original combined data: (2913075, 6)\n",
            "Shape of undersampled data: (1205956, 6)\n",
            "Label distribution in undersampled data:\n",
            "label\n",
            "0    602978\n",
            "1    602978\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "import pandas as pd\n",
        "\n",
        "# Separate features and target from the original combined dataset\n",
        "X = combined_df[['dur','spkts','dpkts','sbytes','dbytes']].values\n",
        "y = df['label'].values # Use the 'label' column with binary labels\n",
        "\n",
        "# Apply RandomUnderSampler\n",
        "rus = RandomUnderSampler(random_state=111)\n",
        "X_undersampled, y_undersampled = rus.fit_resample(X, y)\n",
        "\n",
        "# Create a new DataFrame with undersampled data\n",
        "df_undersampled = pd.DataFrame(X_undersampled, columns=['dur','spkts','dpkts','sbytes','dbytes'])\n",
        "df_undersampled['label'] = y_undersampled # Use 'label' to be consistent with previous steps\n",
        "\n",
        "print(\"Shape of original combined data:\", combined_df.shape)\n",
        "print(\"Shape of undersampled data:\", df_undersampled.shape)\n",
        "print(\"Label distribution in undersampled data:\")\n",
        "print(df_undersampled['label'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "fe2db0ec",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fe2db0ec",
        "outputId": "bd56b039-5f63-439c-c569-17344f26d8ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Graph: <class 'networkx.classes.graph.Graph'>\n",
            "Nodes: 400000, Edges: 200000\n"
          ]
        }
      ],
      "source": [
        "import networkx as nx\n",
        "import numpy as np\n",
        "\n",
        "# ✅ Sample smaller subset (still configurable)\n",
        "df_to_use = df_undersampled.sample(n=200000, random_state=111).reset_index(drop=True)\n",
        "\n",
        "# ✅ Precompute node names efficiently\n",
        "src_nodes = [f\"src_{i}\" for i in df_to_use.index]\n",
        "dst_nodes = [f\"dst_{i}\" for i in df_to_use.index]\n",
        "\n",
        "# ✅ Build edge list directly (no per-row iteration)\n",
        "edges = list(zip(src_nodes, dst_nodes))\n",
        "\n",
        "# ✅ Stack features and labels once\n",
        "edge_features = df_to_use[['dur', 'spkts', 'dpkts', 'sbytes', 'dbytes']].to_numpy(dtype=np.float32)\n",
        "edge_labels = df_to_use['label'].astype(int).to_numpy()\n",
        "\n",
        "# ✅ Create graph directly\n",
        "G = nx.Graph()\n",
        "G.add_nodes_from(src_nodes)\n",
        "G.add_nodes_from(dst_nodes)\n",
        "\n",
        "# ✅ Add edges in one vectorized pass\n",
        "# Using zip with pre-collected arrays avoids inner loops\n",
        "G.add_edges_from(\n",
        "    (src, dst, {'features': feat, 'label': lbl})\n",
        "    for src, dst, feat, lbl in zip(src_nodes, dst_nodes, edge_features, edge_labels)\n",
        ")\n",
        "\n",
        "# ✅ Print info (NetworkX 3.x compatible)\n",
        "print(f\"Graph: {type(G)}\")\n",
        "print(f\"Nodes: {G.number_of_nodes()}, Edges: {G.number_of_edges()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "f95705d2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 830
        },
        "id": "f95705d2",
        "outputId": "a7796ad8-fb16-467b-8d3a-b3c48d58c1e5"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "H = nx.Graph()\n",
        "H.add_edges_from(list(G.edges(data=True))[:10])\n",
        "\n",
        "edge_colors = ['red' if d['label']==1 else 'green' for u,v,d in H.edges(data=True)]\n",
        "pos = nx.spring_layout(H, seed=111)\n",
        "\n",
        "plt.figure(figsize=(12,12))\n",
        "nx.draw(H, pos, with_labels=True, node_size=300, edge_color=edge_colors)\n",
        "plt.title(\"Sample Attack Graph (Red=Attack, Green=Normal)\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96c8cd89",
      "metadata": {
        "id": "96c8cd89"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "1fd8baea",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1fd8baea",
        "outputId": "9ce30589-92df-4921-cf4c-c593dd343a15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ PyG Data ready: Data(x=[400000, 5], edge_index=[2, 200000], edge_attr=[200000, 5], y=[200000])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch_geometric.data import Data\n",
        "import numpy as np\n",
        "\n",
        "# --- 1. Map nodes to integer IDs ---\n",
        "node_mapping = {node: i for i, node in enumerate(G.nodes())}\n",
        "num_nodes = len(node_mapping)\n",
        "\n",
        "# --- 2. Extract edges and their attributes efficiently ---\n",
        "edge_u, edge_v, edge_features, edge_labels = [], [], [], []\n",
        "\n",
        "for i, (u, v, attr) in enumerate(G.edges(data=True)):\n",
        "    edge_u.append(node_mapping[u])\n",
        "    edge_v.append(node_mapping[v])\n",
        "    edge_features.append(np.array(attr[\"features\"], dtype=np.float32))\n",
        "    edge_labels.append(int(attr[\"label\"]))\n",
        "\n",
        "edge_u = np.array(edge_u)\n",
        "edge_v = np.array(edge_v)\n",
        "edges = np.vstack([edge_u, edge_v])\n",
        "\n",
        "# --- 3. Convert to torch tensors ---\n",
        "edge_index = torch.tensor(edges, dtype=torch.long)\n",
        "edge_features = torch.tensor(np.stack(edge_features), dtype=torch.float)\n",
        "edge_labels = torch.tensor(edge_labels, dtype=torch.long)\n",
        "\n",
        "# --- 4. Build node features ---\n",
        "node_features = torch.zeros((num_nodes, edge_features.shape[1]))\n",
        "for i in range(edge_index.shape[1]):\n",
        "    u, v = edge_index[:, i]\n",
        "    node_features[u] += edge_features[i]\n",
        "    node_features[v] += edge_features[i]\n",
        "\n",
        "# Normalize node features\n",
        "norm = node_features.norm(dim=1, keepdim=True)\n",
        "node_features = node_features / (norm + 1e-8)\n",
        "\n",
        "# --- 5. Build Data object ---\n",
        "data = Data(\n",
        "    x=node_features,\n",
        "    edge_index=edge_index,\n",
        "    edge_attr=edge_features,\n",
        "    y=edge_labels\n",
        ")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "data = data.to(device)\n",
        "\n",
        "print(\"✅ PyG Data ready:\", data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "06a6f9d5",
      "metadata": {
        "id": "06a6f9d5"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "# Compute class weights\n",
        "counts = torch.bincount(edge_labels)\n",
        "weights = torch.tensor([1.0 / counts[0], 1.0 / counts[1]], dtype=torch.float).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(weight=weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "fa06630d",
      "metadata": {
        "id": "fa06630d"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import NNConv\n",
        "\n",
        "class EdgeGNN(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
        "        super().__init__()\n",
        "\n",
        "        # MLPs for edge features\n",
        "        nn1 = nn.Sequential(\n",
        "            nn.Linear(in_channels, hidden_channels),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_channels, in_channels * hidden_channels)\n",
        "        )\n",
        "        self.conv1 = NNConv(in_channels, hidden_channels, nn1, aggr='mean')\n",
        "\n",
        "        nn2 = nn.Sequential(\n",
        "            nn.Linear(in_channels, hidden_channels),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_channels, hidden_channels * hidden_channels)\n",
        "        )\n",
        "        self.conv2 = NNConv(hidden_channels, hidden_channels, nn2, aggr='mean')\n",
        "\n",
        "        nn3 = nn.Sequential(\n",
        "            nn.Linear(in_channels, hidden_channels),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_channels, hidden_channels * hidden_channels)\n",
        "        )\n",
        "        self.conv3 = NNConv(hidden_channels, hidden_channels, nn3, aggr='mean')\n",
        "\n",
        "        self.lin = nn.Linear(hidden_channels, out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index, edge_attr):\n",
        "        x = F.gelu(self.conv1(x, edge_index, edge_attr))\n",
        "        x = F.gelu(self.conv2(x, edge_index, edge_attr))\n",
        "        x = F.gelu(self.conv3(x, edge_index, edge_attr))\n",
        "        x = self.lin(x)\n",
        "        return x[edge_index[0]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "jG-gOQJC59GE",
      "metadata": {
        "id": "jG-gOQJC59GE"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "a54174f4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a54174f4",
        "outputId": "6d4cdd07-eb62-415e-88f7-5bb0dcbfcca8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training with learning rate: 0.0005 and epochs: 300\n",
            "Epoch 1/300, Loss: 0.6938, Accuracy: 0.4992\n",
            "Epoch 2/300, Loss: 0.6938, Accuracy: 0.4992\n",
            "Epoch 3/300, Loss: 0.6938, Accuracy: 0.4992\n",
            "Epoch 4/300, Loss: 0.6938, Accuracy: 0.4992\n",
            "Epoch 5/300, Loss: 0.6938, Accuracy: 0.4992\n",
            "Epoch 6/300, Loss: 0.6938, Accuracy: 0.4992\n",
            "Epoch 7/300, Loss: 0.6938, Accuracy: 0.4992\n",
            "Epoch 8/300, Loss: 0.6938, Accuracy: 0.4992\n",
            "Epoch 9/300, Loss: 0.6938, Accuracy: 0.4992\n",
            "Epoch 10/300, Loss: 0.6937, Accuracy: 0.4992\n",
            "Epoch 11/300, Loss: 0.6937, Accuracy: 0.4992\n",
            "Epoch 12/300, Loss: 0.6937, Accuracy: 0.4992\n",
            "Epoch 13/300, Loss: 0.6937, Accuracy: 0.4992\n",
            "Epoch 14/300, Loss: 0.6937, Accuracy: 0.4992\n",
            "Epoch 15/300, Loss: 0.6936, Accuracy: 0.4992\n",
            "Epoch 16/300, Loss: 0.6936, Accuracy: 0.4992\n",
            "Epoch 17/300, Loss: 0.6936, Accuracy: 0.4992\n",
            "Epoch 18/300, Loss: 0.6936, Accuracy: 0.4992\n",
            "Epoch 19/300, Loss: 0.6936, Accuracy: 0.4992\n",
            "Epoch 20/300, Loss: 0.6935, Accuracy: 0.4992\n",
            "Epoch 21/300, Loss: 0.6935, Accuracy: 0.4992\n",
            "Epoch 22/300, Loss: 0.6935, Accuracy: 0.4992\n",
            "Epoch 23/300, Loss: 0.6934, Accuracy: 0.4992\n",
            "Epoch 24/300, Loss: 0.6934, Accuracy: 0.4992\n",
            "Epoch 25/300, Loss: 0.6934, Accuracy: 0.4992\n",
            "Epoch 26/300, Loss: 0.6934, Accuracy: 0.4992\n",
            "Epoch 27/300, Loss: 0.6933, Accuracy: 0.4992\n",
            "Epoch 28/300, Loss: 0.6933, Accuracy: 0.4992\n",
            "Epoch 29/300, Loss: 0.6933, Accuracy: 0.4992\n",
            "Epoch 30/300, Loss: 0.6932, Accuracy: 0.4992\n",
            "Epoch 31/300, Loss: 0.6932, Accuracy: 0.4992\n",
            "Epoch 32/300, Loss: 0.6932, Accuracy: 0.4992\n",
            "Epoch 33/300, Loss: 0.6931, Accuracy: 0.4992\n",
            "Epoch 34/300, Loss: 0.6931, Accuracy: 0.4992\n",
            "Epoch 35/300, Loss: 0.6930, Accuracy: 0.4992\n",
            "Epoch 36/300, Loss: 0.6930, Accuracy: 0.4992\n",
            "Epoch 37/300, Loss: 0.6930, Accuracy: 0.4992\n",
            "Epoch 38/300, Loss: 0.6929, Accuracy: 0.4992\n",
            "Epoch 39/300, Loss: 0.6929, Accuracy: 0.4992\n",
            "Epoch 40/300, Loss: 0.6929, Accuracy: 0.4992\n",
            "Epoch 41/300, Loss: 0.6928, Accuracy: 0.4992\n",
            "Epoch 42/300, Loss: 0.6928, Accuracy: 0.4992\n",
            "Epoch 43/300, Loss: 0.6927, Accuracy: 0.4992\n",
            "Epoch 44/300, Loss: 0.6927, Accuracy: 0.4992\n",
            "Epoch 45/300, Loss: 0.6926, Accuracy: 0.4992\n",
            "Epoch 46/300, Loss: 0.6926, Accuracy: 0.4992\n",
            "Epoch 47/300, Loss: 0.6925, Accuracy: 0.4992\n",
            "Epoch 48/300, Loss: 0.6925, Accuracy: 0.4992\n",
            "Epoch 49/300, Loss: 0.6925, Accuracy: 0.4992\n",
            "Epoch 50/300, Loss: 0.6924, Accuracy: 0.4992\n",
            "Epoch 51/300, Loss: 0.6924, Accuracy: 0.4992\n",
            "Epoch 52/300, Loss: 0.6923, Accuracy: 0.4992\n",
            "Epoch 53/300, Loss: 0.6923, Accuracy: 0.4992\n",
            "Epoch 54/300, Loss: 0.6922, Accuracy: 0.4992\n",
            "Epoch 55/300, Loss: 0.6922, Accuracy: 0.4992\n",
            "Epoch 56/300, Loss: 0.6921, Accuracy: 0.4992\n",
            "Epoch 57/300, Loss: 0.6921, Accuracy: 0.4992\n",
            "Epoch 58/300, Loss: 0.6920, Accuracy: 0.4992\n",
            "Epoch 59/300, Loss: 0.6920, Accuracy: 0.4992\n",
            "Epoch 60/300, Loss: 0.6919, Accuracy: 0.4992\n",
            "Epoch 61/300, Loss: 0.6918, Accuracy: 0.4992\n",
            "Epoch 62/300, Loss: 0.6918, Accuracy: 0.4992\n",
            "Epoch 63/300, Loss: 0.6917, Accuracy: 0.4992\n",
            "Epoch 64/300, Loss: 0.6917, Accuracy: 0.4992\n",
            "Epoch 65/300, Loss: 0.6916, Accuracy: 0.4992\n",
            "Epoch 66/300, Loss: 0.6916, Accuracy: 0.4992\n",
            "Epoch 67/300, Loss: 0.6915, Accuracy: 0.4992\n",
            "Epoch 68/300, Loss: 0.6914, Accuracy: 0.4992\n",
            "Epoch 69/300, Loss: 0.6914, Accuracy: 0.4992\n",
            "Epoch 70/300, Loss: 0.6913, Accuracy: 0.4992\n",
            "Epoch 71/300, Loss: 0.6912, Accuracy: 0.4993\n",
            "Epoch 72/300, Loss: 0.6912, Accuracy: 0.5003\n",
            "Epoch 73/300, Loss: 0.6911, Accuracy: 0.5010\n",
            "Epoch 74/300, Loss: 0.6910, Accuracy: 0.5008\n",
            "Epoch 75/300, Loss: 0.6910, Accuracy: 0.4956\n",
            "Epoch 76/300, Loss: 0.6909, Accuracy: 0.4974\n",
            "Epoch 77/300, Loss: 0.6908, Accuracy: 0.4982\n",
            "Epoch 78/300, Loss: 0.6908, Accuracy: 0.5006\n",
            "Epoch 79/300, Loss: 0.6907, Accuracy: 0.5029\n",
            "Epoch 80/300, Loss: 0.6906, Accuracy: 0.5151\n",
            "Epoch 81/300, Loss: 0.6906, Accuracy: 0.5183\n",
            "Epoch 82/300, Loss: 0.6905, Accuracy: 0.5308\n",
            "Epoch 83/300, Loss: 0.6904, Accuracy: 0.5335\n",
            "Epoch 84/300, Loss: 0.6903, Accuracy: 0.5381\n",
            "Epoch 85/300, Loss: 0.6902, Accuracy: 0.5510\n",
            "Epoch 86/300, Loss: 0.6902, Accuracy: 0.5441\n",
            "Epoch 87/300, Loss: 0.6901, Accuracy: 0.5388\n",
            "Epoch 88/300, Loss: 0.6900, Accuracy: 0.5308\n",
            "Epoch 89/300, Loss: 0.6899, Accuracy: 0.5298\n",
            "Epoch 90/300, Loss: 0.6898, Accuracy: 0.5302\n",
            "Epoch 91/300, Loss: 0.6897, Accuracy: 0.5309\n",
            "Epoch 92/300, Loss: 0.6897, Accuracy: 0.5323\n",
            "Epoch 93/300, Loss: 0.6896, Accuracy: 0.5335\n",
            "Epoch 94/300, Loss: 0.6895, Accuracy: 0.5364\n",
            "Epoch 95/300, Loss: 0.6894, Accuracy: 0.5429\n",
            "Epoch 96/300, Loss: 0.6893, Accuracy: 0.5534\n",
            "Epoch 97/300, Loss: 0.6892, Accuracy: 0.5690\n",
            "Epoch 98/300, Loss: 0.6891, Accuracy: 0.5838\n",
            "Epoch 99/300, Loss: 0.6890, Accuracy: 0.5949\n",
            "Epoch 100/300, Loss: 0.6889, Accuracy: 0.5861\n",
            "Epoch 101/300, Loss: 0.6888, Accuracy: 0.5828\n",
            "Epoch 102/300, Loss: 0.6887, Accuracy: 0.5844\n",
            "Epoch 103/300, Loss: 0.6886, Accuracy: 0.5853\n",
            "Epoch 104/300, Loss: 0.6885, Accuracy: 0.5851\n",
            "Epoch 105/300, Loss: 0.6884, Accuracy: 0.5860\n",
            "Epoch 106/300, Loss: 0.6883, Accuracy: 0.5859\n",
            "Epoch 107/300, Loss: 0.6882, Accuracy: 0.5859\n",
            "Epoch 108/300, Loss: 0.6880, Accuracy: 0.5857\n",
            "Epoch 109/300, Loss: 0.6879, Accuracy: 0.5858\n",
            "Epoch 110/300, Loss: 0.6878, Accuracy: 0.5847\n",
            "Epoch 111/300, Loss: 0.6877, Accuracy: 0.5845\n",
            "Epoch 112/300, Loss: 0.6876, Accuracy: 0.5844\n",
            "Epoch 113/300, Loss: 0.6874, Accuracy: 0.5843\n",
            "Epoch 114/300, Loss: 0.6873, Accuracy: 0.5842\n",
            "Epoch 115/300, Loss: 0.6872, Accuracy: 0.5843\n",
            "Epoch 116/300, Loss: 0.6871, Accuracy: 0.5843\n",
            "Epoch 117/300, Loss: 0.6869, Accuracy: 0.5843\n",
            "Epoch 118/300, Loss: 0.6868, Accuracy: 0.5842\n",
            "Epoch 119/300, Loss: 0.6867, Accuracy: 0.5845\n",
            "Epoch 120/300, Loss: 0.6865, Accuracy: 0.5844\n",
            "Epoch 121/300, Loss: 0.6864, Accuracy: 0.5844\n",
            "Epoch 122/300, Loss: 0.6862, Accuracy: 0.5849\n",
            "Epoch 123/300, Loss: 0.6861, Accuracy: 0.5851\n",
            "Epoch 124/300, Loss: 0.6859, Accuracy: 0.5851\n",
            "Epoch 125/300, Loss: 0.6858, Accuracy: 0.5851\n",
            "Epoch 126/300, Loss: 0.6856, Accuracy: 0.5850\n",
            "Epoch 127/300, Loss: 0.6855, Accuracy: 0.5849\n",
            "Epoch 128/300, Loss: 0.6853, Accuracy: 0.5849\n",
            "Epoch 129/300, Loss: 0.6851, Accuracy: 0.5848\n",
            "Epoch 130/300, Loss: 0.6850, Accuracy: 0.5848\n",
            "Epoch 131/300, Loss: 0.6848, Accuracy: 0.5848\n",
            "Epoch 132/300, Loss: 0.6846, Accuracy: 0.5848\n",
            "Epoch 133/300, Loss: 0.6845, Accuracy: 0.5847\n",
            "Epoch 134/300, Loss: 0.6843, Accuracy: 0.5847\n",
            "Epoch 135/300, Loss: 0.6841, Accuracy: 0.5847\n",
            "Epoch 136/300, Loss: 0.6839, Accuracy: 0.5846\n",
            "Epoch 137/300, Loss: 0.6837, Accuracy: 0.5846\n",
            "Epoch 138/300, Loss: 0.6835, Accuracy: 0.5846\n",
            "Epoch 139/300, Loss: 0.6833, Accuracy: 0.5846\n",
            "Epoch 140/300, Loss: 0.6831, Accuracy: 0.5845\n",
            "Epoch 141/300, Loss: 0.6829, Accuracy: 0.5845\n",
            "Epoch 142/300, Loss: 0.6827, Accuracy: 0.5845\n",
            "Epoch 143/300, Loss: 0.6825, Accuracy: 0.5844\n",
            "Epoch 144/300, Loss: 0.6823, Accuracy: 0.5844\n",
            "Epoch 145/300, Loss: 0.6821, Accuracy: 0.5844\n",
            "Epoch 146/300, Loss: 0.6819, Accuracy: 0.5844\n",
            "Epoch 147/300, Loss: 0.6817, Accuracy: 0.5844\n",
            "Epoch 148/300, Loss: 0.6814, Accuracy: 0.5844\n",
            "Epoch 149/300, Loss: 0.6812, Accuracy: 0.5844\n",
            "Epoch 150/300, Loss: 0.6810, Accuracy: 0.5844\n",
            "Epoch 151/300, Loss: 0.6807, Accuracy: 0.5844\n",
            "Epoch 152/300, Loss: 0.6805, Accuracy: 0.5844\n",
            "Epoch 153/300, Loss: 0.6803, Accuracy: 0.5844\n",
            "Epoch 154/300, Loss: 0.6800, Accuracy: 0.5844\n",
            "Epoch 155/300, Loss: 0.6798, Accuracy: 0.5844\n",
            "Epoch 156/300, Loss: 0.6795, Accuracy: 0.5844\n",
            "Epoch 157/300, Loss: 0.6793, Accuracy: 0.5844\n",
            "Epoch 158/300, Loss: 0.6790, Accuracy: 0.5844\n",
            "Epoch 159/300, Loss: 0.6787, Accuracy: 0.5844\n",
            "Epoch 160/300, Loss: 0.6785, Accuracy: 0.5844\n",
            "Epoch 161/300, Loss: 0.6782, Accuracy: 0.5844\n",
            "Epoch 162/300, Loss: 0.6779, Accuracy: 0.5843\n",
            "Epoch 163/300, Loss: 0.6777, Accuracy: 0.5843\n",
            "Epoch 164/300, Loss: 0.6774, Accuracy: 0.5843\n",
            "Epoch 165/300, Loss: 0.6771, Accuracy: 0.5843\n",
            "Epoch 166/300, Loss: 0.6768, Accuracy: 0.5843\n",
            "Epoch 167/300, Loss: 0.6765, Accuracy: 0.5843\n",
            "Epoch 168/300, Loss: 0.6762, Accuracy: 0.5843\n",
            "Epoch 169/300, Loss: 0.6759, Accuracy: 0.5843\n",
            "Epoch 170/300, Loss: 0.6756, Accuracy: 0.5843\n",
            "Epoch 171/300, Loss: 0.6753, Accuracy: 0.5843\n",
            "Epoch 172/300, Loss: 0.6750, Accuracy: 0.5843\n",
            "Epoch 173/300, Loss: 0.6747, Accuracy: 0.5843\n",
            "Epoch 174/300, Loss: 0.6744, Accuracy: 0.5843\n",
            "Epoch 175/300, Loss: 0.6741, Accuracy: 0.5843\n",
            "Epoch 176/300, Loss: 0.6738, Accuracy: 0.5843\n",
            "Epoch 177/300, Loss: 0.6735, Accuracy: 0.5843\n",
            "Epoch 178/300, Loss: 0.6731, Accuracy: 0.5843\n",
            "Epoch 179/300, Loss: 0.6728, Accuracy: 0.5843\n",
            "Epoch 180/300, Loss: 0.6725, Accuracy: 0.5843\n",
            "Epoch 181/300, Loss: 0.6722, Accuracy: 0.5843\n",
            "Epoch 182/300, Loss: 0.6719, Accuracy: 0.5843\n",
            "Epoch 183/300, Loss: 0.6715, Accuracy: 0.5843\n",
            "Epoch 184/300, Loss: 0.6712, Accuracy: 0.5843\n",
            "Epoch 185/300, Loss: 0.6709, Accuracy: 0.5843\n",
            "Epoch 186/300, Loss: 0.6705, Accuracy: 0.5843\n",
            "Epoch 187/300, Loss: 0.6702, Accuracy: 0.5843\n",
            "Epoch 188/300, Loss: 0.6699, Accuracy: 0.5843\n",
            "Epoch 189/300, Loss: 0.6695, Accuracy: 0.5843\n",
            "Epoch 190/300, Loss: 0.6692, Accuracy: 0.5843\n",
            "Epoch 191/300, Loss: 0.6688, Accuracy: 0.5845\n",
            "Epoch 192/300, Loss: 0.6685, Accuracy: 0.5846\n",
            "Epoch 193/300, Loss: 0.6682, Accuracy: 0.5846\n",
            "Epoch 194/300, Loss: 0.6678, Accuracy: 0.5846\n",
            "Epoch 195/300, Loss: 0.6675, Accuracy: 0.5846\n",
            "Epoch 196/300, Loss: 0.6671, Accuracy: 0.5846\n",
            "Epoch 197/300, Loss: 0.6668, Accuracy: 0.5846\n",
            "Epoch 198/300, Loss: 0.6664, Accuracy: 0.5846\n",
            "Epoch 199/300, Loss: 0.6661, Accuracy: 0.5846\n",
            "Epoch 200/300, Loss: 0.6657, Accuracy: 0.5847\n",
            "Epoch 201/300, Loss: 0.6654, Accuracy: 0.5847\n",
            "Epoch 202/300, Loss: 0.6651, Accuracy: 0.5847\n",
            "Epoch 203/300, Loss: 0.6647, Accuracy: 0.5847\n",
            "Epoch 204/300, Loss: 0.6644, Accuracy: 0.5847\n",
            "Epoch 205/300, Loss: 0.6640, Accuracy: 0.5847\n",
            "Epoch 206/300, Loss: 0.6637, Accuracy: 0.5847\n",
            "Epoch 207/300, Loss: 0.6633, Accuracy: 0.5847\n",
            "Epoch 208/300, Loss: 0.6630, Accuracy: 0.5847\n",
            "Epoch 209/300, Loss: 0.6626, Accuracy: 0.5847\n",
            "Epoch 210/300, Loss: 0.6623, Accuracy: 0.5848\n",
            "Epoch 211/300, Loss: 0.6619, Accuracy: 0.5848\n",
            "Epoch 212/300, Loss: 0.6616, Accuracy: 0.5849\n",
            "Epoch 213/300, Loss: 0.6612, Accuracy: 0.5849\n",
            "Epoch 214/300, Loss: 0.6609, Accuracy: 0.5849\n",
            "Epoch 215/300, Loss: 0.6605, Accuracy: 0.5849\n",
            "Epoch 216/300, Loss: 0.6602, Accuracy: 0.5849\n",
            "Epoch 217/300, Loss: 0.6598, Accuracy: 0.5849\n",
            "Epoch 218/300, Loss: 0.6595, Accuracy: 0.5850\n",
            "Epoch 219/300, Loss: 0.6591, Accuracy: 0.5850\n",
            "Epoch 220/300, Loss: 0.6588, Accuracy: 0.5851\n",
            "Epoch 221/300, Loss: 0.6584, Accuracy: 0.5851\n",
            "Epoch 222/300, Loss: 0.6581, Accuracy: 0.5852\n",
            "Epoch 223/300, Loss: 0.6577, Accuracy: 0.5851\n",
            "Epoch 224/300, Loss: 0.6574, Accuracy: 0.5852\n",
            "Epoch 225/300, Loss: 0.6570, Accuracy: 0.5852\n",
            "Epoch 226/300, Loss: 0.6566, Accuracy: 0.5852\n",
            "Epoch 227/300, Loss: 0.6563, Accuracy: 0.5853\n",
            "Epoch 228/300, Loss: 0.6559, Accuracy: 0.5853\n",
            "Epoch 229/300, Loss: 0.6556, Accuracy: 0.5853\n",
            "Epoch 230/300, Loss: 0.6552, Accuracy: 0.5856\n",
            "Epoch 231/300, Loss: 0.6548, Accuracy: 0.5852\n",
            "Epoch 232/300, Loss: 0.6545, Accuracy: 0.5855\n",
            "Epoch 233/300, Loss: 0.6541, Accuracy: 0.5860\n",
            "Epoch 234/300, Loss: 0.6537, Accuracy: 0.5862\n",
            "Epoch 235/300, Loss: 0.6534, Accuracy: 0.5864\n",
            "Epoch 236/300, Loss: 0.6530, Accuracy: 0.5865\n",
            "Epoch 237/300, Loss: 0.6526, Accuracy: 0.5868\n",
            "Epoch 238/300, Loss: 0.6522, Accuracy: 0.5870\n",
            "Epoch 239/300, Loss: 0.6518, Accuracy: 0.5873\n",
            "Epoch 240/300, Loss: 0.6515, Accuracy: 0.5874\n",
            "Epoch 241/300, Loss: 0.6511, Accuracy: 0.5877\n",
            "Epoch 242/300, Loss: 0.6507, Accuracy: 0.5879\n",
            "Epoch 243/300, Loss: 0.6503, Accuracy: 0.5885\n",
            "Epoch 244/300, Loss: 0.6499, Accuracy: 0.5889\n",
            "Epoch 245/300, Loss: 0.6495, Accuracy: 0.5891\n",
            "Epoch 246/300, Loss: 0.6491, Accuracy: 0.5893\n",
            "Epoch 247/300, Loss: 0.6487, Accuracy: 0.5895\n",
            "Epoch 248/300, Loss: 0.6483, Accuracy: 0.5900\n",
            "Epoch 249/300, Loss: 0.6479, Accuracy: 0.5905\n",
            "Epoch 250/300, Loss: 0.6475, Accuracy: 0.5906\n",
            "Epoch 251/300, Loss: 0.6471, Accuracy: 0.5907\n",
            "Epoch 252/300, Loss: 0.6466, Accuracy: 0.5907\n",
            "Epoch 253/300, Loss: 0.6462, Accuracy: 0.5908\n",
            "Epoch 254/300, Loss: 0.6458, Accuracy: 0.5908\n",
            "Epoch 255/300, Loss: 0.6454, Accuracy: 0.5909\n",
            "Epoch 256/300, Loss: 0.6449, Accuracy: 0.5909\n",
            "Epoch 257/300, Loss: 0.6445, Accuracy: 0.5909\n",
            "Epoch 258/300, Loss: 0.6441, Accuracy: 0.5909\n",
            "Epoch 259/300, Loss: 0.6436, Accuracy: 0.5910\n",
            "Epoch 260/300, Loss: 0.6432, Accuracy: 0.5910\n",
            "Epoch 261/300, Loss: 0.6427, Accuracy: 0.5911\n",
            "Epoch 262/300, Loss: 0.6422, Accuracy: 0.5912\n",
            "Epoch 263/300, Loss: 0.6418, Accuracy: 0.5913\n",
            "Epoch 264/300, Loss: 0.6413, Accuracy: 0.5913\n",
            "Epoch 265/300, Loss: 0.6409, Accuracy: 0.5913\n",
            "Epoch 266/300, Loss: 0.6404, Accuracy: 0.5914\n",
            "Epoch 267/300, Loss: 0.6399, Accuracy: 0.5914\n",
            "Epoch 268/300, Loss: 0.6394, Accuracy: 0.5915\n",
            "Epoch 269/300, Loss: 0.6389, Accuracy: 0.5916\n",
            "Epoch 270/300, Loss: 0.6384, Accuracy: 0.5917\n",
            "Epoch 271/300, Loss: 0.6380, Accuracy: 0.5918\n",
            "Epoch 272/300, Loss: 0.6375, Accuracy: 0.5918\n",
            "Epoch 273/300, Loss: 0.6369, Accuracy: 0.5919\n",
            "Epoch 274/300, Loss: 0.6364, Accuracy: 0.5919\n",
            "Epoch 275/300, Loss: 0.6359, Accuracy: 0.5920\n",
            "Epoch 276/300, Loss: 0.6354, Accuracy: 0.5920\n",
            "Epoch 277/300, Loss: 0.6349, Accuracy: 0.5921\n",
            "Epoch 278/300, Loss: 0.6344, Accuracy: 0.5920\n",
            "Epoch 279/300, Loss: 0.6338, Accuracy: 0.5921\n",
            "Epoch 280/300, Loss: 0.6333, Accuracy: 0.5921\n",
            "Epoch 281/300, Loss: 0.6328, Accuracy: 0.5921\n",
            "Epoch 282/300, Loss: 0.6322, Accuracy: 0.5932\n",
            "Epoch 283/300, Loss: 0.6317, Accuracy: 0.5933\n",
            "Epoch 284/300, Loss: 0.6311, Accuracy: 0.5932\n",
            "Epoch 285/300, Loss: 0.6306, Accuracy: 0.5932\n",
            "Epoch 286/300, Loss: 0.6300, Accuracy: 0.5932\n",
            "Epoch 287/300, Loss: 0.6295, Accuracy: 0.5933\n",
            "Epoch 288/300, Loss: 0.6289, Accuracy: 0.5932\n",
            "Epoch 289/300, Loss: 0.6283, Accuracy: 0.5932\n",
            "Epoch 290/300, Loss: 0.6277, Accuracy: 0.5933\n",
            "Epoch 291/300, Loss: 0.6272, Accuracy: 0.5933\n",
            "Epoch 292/300, Loss: 0.6266, Accuracy: 0.5934\n",
            "Epoch 293/300, Loss: 0.6260, Accuracy: 0.5934\n",
            "Epoch 294/300, Loss: 0.6254, Accuracy: 0.5933\n",
            "Epoch 295/300, Loss: 0.6248, Accuracy: 0.5934\n",
            "Epoch 296/300, Loss: 0.6242, Accuracy: 0.5934\n",
            "Epoch 297/300, Loss: 0.6236, Accuracy: 0.5935\n",
            "Epoch 298/300, Loss: 0.6230, Accuracy: 0.5935\n",
            "Epoch 299/300, Loss: 0.6224, Accuracy: 0.5936\n",
            "Epoch 300/300, Loss: 0.6218, Accuracy: 0.5937\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn # Import nn for CrossEntropyLoss\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# Compute class weights based on the undersampled data\n",
        "counts = torch.bincount(data.y)\n",
        "# No need for explicit weights if data is balanced, but keep for consistency if desired\n",
        "# weights = torch.tensor([1.0 / counts[0], 1.0 / counts[1]], dtype=torch.float).to(device)\n",
        "# criterion = nn.CrossEntropyLoss(weight=weights) # Use the updated criterion\n",
        "criterion = nn.CrossEntropyLoss() # Use standard CrossEntropyLoss for balanced data\n",
        "\n",
        "\n",
        "model = EdgeGNN(in_channels=edge_features.shape[1], hidden_channels=64, out_channels=2).to(device)\n",
        "optimizer = optim.RAdam(model.parameters(), lr=0.0005) # Using the learning rate that worked best before\n",
        "epochs = 300 # Using the number of epochs that worked best before\n",
        "\n",
        "print(f\"Training with learning rate: {optimizer.defaults['lr']} and epochs: {epochs}\")\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data.x, data.edge_index, data.edge_attr)\n",
        "    loss = criterion(out, data.y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Calculate accuracy after each epoch\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        preds = out.argmax(dim=1)\n",
        "        acc = (preds == data.y).sum().item() / data.y.size(0)\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.item():.4f}, Accuracy: {acc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "1dbac3ad",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dbac3ad",
        "outputId": "71faa54c-dad8-4451-82d1-33e56b1666a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.90      0.69    100156\n",
            "           1       0.74      0.28      0.41     99844\n",
            "\n",
            "    accuracy                           0.59    200000\n",
            "   macro avg       0.65      0.59      0.55    200000\n",
            "weighted avg       0.65      0.59      0.55    200000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    out = model(data.x, data.edge_index, data.edge_attr)\n",
        "    probs = torch.softmax(out, dim=1)[:, 1]\n",
        "    preds = (probs > 0.5).long().cpu().numpy()\n",
        "    true = data.y.cpu().numpy()\n",
        "\n",
        "print(classification_report(true, preds, zero_division=0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "dd07b184",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "dd07b184",
        "outputId": "e4a8cfde-e67c-49e7-fbb2-3b584c3010ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ GPU memory optimized\n",
            "Training on cuda\n",
            "Training with lr=0.0004, epochs=300, hidden=96\n",
            "\n",
            "🔥 New Best Accuracy: 0.6230 at epoch 1\n",
            "🔥 New Best Accuracy: 0.6258 at epoch 2\n",
            "🔥 New Best Accuracy: 0.6357 at epoch 3\n",
            "🔥 New Best Accuracy: 0.6587 at epoch 4\n",
            "🔥 New Best Accuracy: 0.6635 at epoch 5\n",
            "🔥 New Best Accuracy: 0.6646 at epoch 6\n",
            "🔥 New Best Accuracy: 0.7369 at epoch 8\n",
            "🔥 New Best Accuracy: 0.7538 at epoch 9\n",
            "Epoch [ 10/300] | Loss: 0.5891 | Train Acc: 0.6810 | Val Acc: 0.7199 | LR: 3.99e-04\n",
            "🔥 New Best Accuracy: 0.7787 at epoch 12\n",
            "Epoch [ 20/300] | Loss: 0.5378 | Train Acc: 0.7420 | Val Acc: 0.7453 | LR: 3.96e-04\n",
            "🔥 New Best Accuracy: 0.7861 at epoch 23\n",
            "🔥 New Best Accuracy: 0.8101 at epoch 26\n",
            "Epoch [ 30/300] | Loss: 0.5162 | Train Acc: 0.7731 | Val Acc: 0.7920 | LR: 3.90e-04\n",
            "🔥 New Best Accuracy: 0.8117 at epoch 32\n",
            "Epoch [ 40/300] | Loss: 0.5103 | Train Acc: 0.7590 | Val Acc: 0.7896 | LR: 3.83e-04\n",
            "Epoch [ 50/300] | Loss: 0.4945 | Train Acc: 0.7717 | Val Acc: 0.8030 | LR: 3.73e-04\n",
            "🔥 New Best Accuracy: 0.8118 at epoch 58\n",
            "Epoch [ 60/300] | Loss: 0.4890 | Train Acc: 0.7888 | Val Acc: 0.7912 | LR: 3.62e-04\n",
            "🔥 New Best Accuracy: 0.8322 at epoch 63\n",
            "Epoch [ 70/300] | Loss: 0.4884 | Train Acc: 0.7857 | Val Acc: 0.8002 | LR: 3.49e-04\n",
            "🔥 New Best Accuracy: 0.8387 at epoch 78\n",
            "Epoch [ 80/300] | Loss: 0.4679 | Train Acc: 0.8056 | Val Acc: 0.8185 | LR: 3.34e-04\n",
            "Epoch [ 90/300] | Loss: 0.4560 | Train Acc: 0.8151 | Val Acc: 0.8089 | LR: 3.18e-04\n",
            "🔥 New Best Accuracy: 0.8449 at epoch 95\n",
            "Epoch [100/300] | Loss: 0.4639 | Train Acc: 0.7973 | Val Acc: 0.8316 | LR: 3.01e-04\n",
            "🔥 New Best Accuracy: 0.8465 at epoch 105\n",
            "Epoch [110/300] | Loss: 0.4537 | Train Acc: 0.8131 | Val Acc: 0.8426 | LR: 2.83e-04\n",
            "🔥 New Best Accuracy: 0.8506 at epoch 112\n",
            "Epoch [120/300] | Loss: 0.4675 | Train Acc: 0.7908 | Val Acc: 0.7997 | LR: 2.63e-04\n",
            "Epoch [130/300] | Loss: 0.4581 | Train Acc: 0.7993 | Val Acc: 0.8162 | LR: 2.43e-04\n",
            "Epoch [140/300] | Loss: 0.4406 | Train Acc: 0.8285 | Val Acc: 0.8214 | LR: 2.23e-04\n",
            "Epoch [150/300] | Loss: 0.4481 | Train Acc: 0.8140 | Val Acc: 0.8320 | LR: 2.02e-04\n",
            "Epoch [160/300] | Loss: 0.4633 | Train Acc: 0.7940 | Val Acc: 0.8364 | LR: 1.81e-04\n",
            "Epoch [170/300] | Loss: 0.4336 | Train Acc: 0.8333 | Val Acc: 0.8227 | LR: 1.61e-04\n",
            "Epoch [180/300] | Loss: 0.4369 | Train Acc: 0.8290 | Val Acc: 0.8398 | LR: 1.41e-04\n",
            "Epoch [190/300] | Loss: 0.4321 | Train Acc: 0.8360 | Val Acc: 0.8377 | LR: 1.21e-04\n",
            "🔥 New Best Accuracy: 0.8509 at epoch 191\n",
            "Epoch [200/300] | Loss: 0.4323 | Train Acc: 0.8299 | Val Acc: 0.8452 | LR: 1.03e-04\n",
            "🔥 New Best Accuracy: 0.8547 at epoch 209\n",
            "Epoch [210/300] | Loss: 0.4436 | Train Acc: 0.8255 | Val Acc: 0.7605 | LR: 8.56e-05\n",
            "Epoch [220/300] | Loss: 0.4319 | Train Acc: 0.8337 | Val Acc: 0.8502 | LR: 6.95e-05\n",
            "Epoch [230/300] | Loss: 0.4273 | Train Acc: 0.8361 | Val Acc: 0.8375 | LR: 5.49e-05\n",
            "Epoch [240/300] | Loss: 0.4274 | Train Acc: 0.8404 | Val Acc: 0.8349 | LR: 4.18e-05\n",
            "Epoch [250/300] | Loss: 0.4248 | Train Acc: 0.8389 | Val Acc: 0.8465 | LR: 3.05e-05\n",
            "Epoch [260/300] | Loss: 0.4246 | Train Acc: 0.8375 | Val Acc: 0.8494 | LR: 2.11e-05\n",
            "Epoch [270/300] | Loss: 0.4250 | Train Acc: 0.8381 | Val Acc: 0.8427 | LR: 1.37e-05\n",
            "Epoch [280/300] | Loss: 0.4251 | Train Acc: 0.8390 | Val Acc: 0.8442 | LR: 8.33e-06\n",
            "Epoch [290/300] | Loss: 0.4242 | Train Acc: 0.8395 | Val Acc: 0.8448 | LR: 5.08e-06\n",
            "Epoch [300/300] | Loss: 0.4288 | Train Acc: 0.8338 | Val Acc: 0.8445 | LR: 4.00e-06\n",
            "\n",
            "==================================================\n",
            "🏆 TRAINING COMPLETE\n",
            "Best Accuracy: 0.8547\n",
            "==================================================\n",
            "\n",
            "Classification Report:\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Found input variables with inconsistent numbers of samples: [200000, 50000]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2868917070.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m \u001b[0mbest_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrained_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_and_evaluate_optimized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[0;31m# Optional: Test different learning rates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2868917070.py\u001b[0m in \u001b[0;36mtrain_and_evaluate_optimized\u001b[0;34m(data, lr, epochs, batch_size)\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[0;31m# Detailed classification report\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Classification Report:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m     print(classification_report(\n\u001b[0m\u001b[1;32m    283\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0mbest_preds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                     )\n\u001b[1;32m    215\u001b[0m                 ):\n\u001b[0;32m--> 216\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[1;32m   2669\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2670\u001b[0m     \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattach_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2671\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2673\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \"\"\"\n\u001b[1;32m     97\u001b[0m     \u001b[0mxp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_namespace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y_true\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y_pred\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    476\u001b[0m             \u001b[0;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0;34m%\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [200000, 50000]"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import NNConv, LayerNorm\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "\n",
        "# Clear GPU cache at start\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# ============================================================\n",
        "# ✅ Enhanced Feature Normalization\n",
        "# ============================================================\n",
        "def normalize_features(data):\n",
        "    \"\"\"Normalize node and edge features\"\"\"\n",
        "    device = data.x.device\n",
        "\n",
        "    # Normalize edge features\n",
        "    if data.edge_attr is not None:\n",
        "        edge_attr_np = data.edge_attr.cpu().numpy()\n",
        "        if edge_attr_np.size > 0:\n",
        "            s_edge = StandardScaler()\n",
        "            edge_attr_np = s_edge.fit_transform(edge_attr_np)\n",
        "            edge_attr_np = np.nan_to_num(edge_attr_np, nan=0.0)\n",
        "            data.edge_attr = torch.tensor(edge_attr_np, dtype=torch.float, device=device)\n",
        "\n",
        "    # Normalize node features\n",
        "    if data.x is not None:\n",
        "        x_np = data.x.cpu().numpy()\n",
        "        if x_np.size > 0:\n",
        "            s_x = StandardScaler()\n",
        "            x_np = s_x.fit_transform(x_np)\n",
        "            x_np = np.nan_to_num(x_np, nan=0.0)\n",
        "            data.x = torch.tensor(x_np, dtype=torch.float, device=device)\n",
        "\n",
        "    return data\n",
        "\n",
        "# Apply normalization\n",
        "data = normalize_features(data)\n",
        "\n",
        "# ============================================================\n",
        "# ✅ Optimized EdgeGNN with Hidden Layers = 96\n",
        "# ============================================================\n",
        "class OptimizedEdgeGNN(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, dropout=0.4):\n",
        "        super().__init__()\n",
        "        self.hidden_channels = 96  # Fixed as requested\n",
        "\n",
        "        # Edge feature networks (optimized)\n",
        "        self.edge_net1 = nn.Sequential(\n",
        "            nn.Linear(data.edge_attr.shape[1], 64),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout * 0.3),\n",
        "            nn.Linear(64, in_channels * self.hidden_channels)\n",
        "        )\n",
        "\n",
        "        self.edge_net2 = nn.Sequential(\n",
        "            nn.Linear(data.edge_attr.shape[1], 64),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout * 0.3),\n",
        "            nn.Linear(64, self.hidden_channels * self.hidden_channels)\n",
        "        )\n",
        "\n",
        "        # Convolution layers\n",
        "        self.conv1 = NNConv(in_channels, self.hidden_channels, self.edge_net1, aggr='mean')\n",
        "        self.conv2 = NNConv(self.hidden_channels, self.hidden_channels, self.edge_net2, aggr='mean')\n",
        "\n",
        "        # Normalization layers (LayerNorm is more memory efficient)\n",
        "        self.norm1 = LayerNorm(self.hidden_channels)\n",
        "        self.norm2 = LayerNorm(self.hidden_channels)\n",
        "\n",
        "        # Skip connection projection\n",
        "        self.skip_proj = nn.Linear(in_channels, self.hidden_channels)\n",
        "\n",
        "        # Output layers\n",
        "        self.output_mlp = nn.Sequential(\n",
        "            nn.Linear(self.hidden_channels, 48),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.LayerNorm(48),\n",
        "            nn.Linear(48, out_channels)\n",
        "        )\n",
        "\n",
        "        # Initialize weights properly\n",
        "        self._init_weights()\n",
        "\n",
        "    def _init_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_in', nonlinearity='relu')\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def forward(self, x, edge_index, edge_attr):\n",
        "        # First convolution with residual connection\n",
        "        identity = self.skip_proj(x)\n",
        "        x1 = self.conv1(x, edge_index, edge_attr)\n",
        "        x1 = self.norm1(x1)\n",
        "        x1 = F.gelu(x1 + identity)  # Residual connection\n",
        "\n",
        "        # Second convolution\n",
        "        x2 = self.conv2(x1, edge_index, edge_attr)\n",
        "        x2 = self.norm2(x2)\n",
        "        x2 = F.gelu(x2)\n",
        "\n",
        "        # Apply dropout\n",
        "        x2 = F.dropout(x2, p=0.4, training=self.training)\n",
        "\n",
        "        # Get edge source node features and apply output MLP\n",
        "        edge_sources = x2[edge_index[0]]\n",
        "        return self.output_mlp(edge_sources)\n",
        "\n",
        "# ============================================================\n",
        "# ✅ Training Function (No Early Stopping)\n",
        "# ============================================================\n",
        "def train_and_evaluate_optimized(data, lr=4e-4, epochs=300, batch_size=25000):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Training on {device}\")\n",
        "\n",
        "    # Create model with fixed 96 hidden channels\n",
        "    model = OptimizedEdgeGNN(\n",
        "        in_channels=data.x.shape[1],\n",
        "        out_channels=2,\n",
        "        dropout=0.4\n",
        "    ).to(device)\n",
        "\n",
        "    # Optimizer with weight decay\n",
        "    optimizer = torch.optim.AdamW(\n",
        "        model.parameters(),\n",
        "        lr=lr,\n",
        "        weight_decay=1e-4,\n",
        "        betas=(0.9, 0.99)\n",
        "    )\n",
        "\n",
        "    # Cosine annealing scheduler\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
        "        optimizer,\n",
        "        T_max=epochs,\n",
        "        eta_min=lr * 0.01\n",
        "    )\n",
        "\n",
        "    # Label smoothing for better generalization\n",
        "    criterion = nn.CrossEntropyLoss(label_smoothing=0.05)\n",
        "\n",
        "    num_edges = data.edge_index.shape[1]\n",
        "    best_acc = 0.0\n",
        "    best_preds = None\n",
        "\n",
        "    print(f\"Training with lr={lr}, epochs={epochs}, hidden=96\\n\")\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        total_correct = 0\n",
        "        total_samples = 0\n",
        "\n",
        "        # Use batch training for memory efficiency\n",
        "        if batch_size and batch_size < num_edges:\n",
        "            # Shuffle edges for each epoch\n",
        "            indices = torch.randperm(num_edges, device=device)\n",
        "\n",
        "            for start in range(0, num_edges, batch_size):\n",
        "                end = min(start + batch_size, num_edges)\n",
        "                batch_idx = indices[start:end]\n",
        "\n",
        "                optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "                # Get batch data\n",
        "                edge_index_batch = data.edge_index[:, batch_idx]\n",
        "                edge_attr_batch = data.edge_attr[batch_idx]\n",
        "                labels_batch = data.y[batch_idx]\n",
        "\n",
        "                # Forward pass\n",
        "                out = model(data.x, edge_index_batch, edge_attr_batch)\n",
        "\n",
        "                # Skip if NaN\n",
        "                if torch.isnan(out).any():\n",
        "                    continue\n",
        "\n",
        "                # Loss calculation\n",
        "                loss = criterion(out, labels_batch)\n",
        "\n",
        "                # Backward pass with gradient accumulation\n",
        "                loss.backward()\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "                optimizer.step()\n",
        "                optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "                # Track metrics\n",
        "                total_loss += loss.item() * len(labels_batch)\n",
        "                preds = out.argmax(dim=1)\n",
        "                total_correct += (preds == labels_batch).sum().item()\n",
        "                total_samples += len(labels_batch)\n",
        "        else:\n",
        "            # Full batch training\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "            out = model(data.x, data.edge_index, data.edge_attr)\n",
        "\n",
        "            if torch.isnan(out).any():\n",
        "                print(\"⚠️ NaN detected. Skipping epoch.\")\n",
        "                continue\n",
        "\n",
        "            loss = criterion(out, data.y)\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss = loss.item() * num_edges\n",
        "            preds = out.argmax(dim=1)\n",
        "            total_correct = (preds == data.y).sum().item()\n",
        "            total_samples = num_edges\n",
        "\n",
        "        # Update learning rate\n",
        "        scheduler.step()\n",
        "\n",
        "        # Evaluation\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            # Use small batches for evaluation to save memory\n",
        "            eval_acc = 0\n",
        "            eval_samples = 0\n",
        "\n",
        "            if num_edges > 50000:  # Large graph, evaluate in batches\n",
        "                eval_batch_size = min(50000, num_edges)\n",
        "                for start in range(0, num_edges, eval_batch_size):\n",
        "                    end = min(start + eval_batch_size, num_edges)\n",
        "                    edge_index_batch = data.edge_index[:, start:end]\n",
        "                    edge_attr_batch = data.edge_attr[start:end]\n",
        "                    labels_batch = data.y[start:end]\n",
        "\n",
        "                    out = model(data.x, edge_index_batch, edge_attr_batch)\n",
        "                    preds = out.argmax(dim=1)\n",
        "                    eval_acc += (preds == labels_batch).sum().item()\n",
        "                    eval_samples += len(labels_batch)\n",
        "\n",
        "                acc = eval_acc / eval_samples\n",
        "            else:\n",
        "                # Full evaluation for smaller graphs\n",
        "                out = model(data.x, data.edge_index, data.edge_attr)\n",
        "                preds = out.argmax(dim=1)\n",
        "                acc = (preds == data.y).float().mean().item()\n",
        "\n",
        "        # Track best accuracy\n",
        "        if acc > best_acc:\n",
        "            best_acc = acc\n",
        "            best_preds = preds.clone()\n",
        "            print(f\"🔥 New Best Accuracy: {best_acc:.4f} at epoch {epoch+1}\")\n",
        "\n",
        "        # Print progress every 10 epochs\n",
        "        if (epoch + 1) % 10 == 0:\n",
        "            avg_loss = total_loss / total_samples if total_samples > 0 else 0\n",
        "            train_acc = total_correct / total_samples if total_samples > 0 else 0\n",
        "            current_lr = optimizer.param_groups[0]['lr']\n",
        "            print(f\"Epoch [{epoch+1:3d}/{epochs}] | \"\n",
        "                  f\"Loss: {avg_loss:.4f} | \"\n",
        "                  f\"Train Acc: {train_acc:.4f} | \"\n",
        "                  f\"Val Acc: {acc:.4f} | \"\n",
        "                  f\"LR: {current_lr:.2e}\")\n",
        "\n",
        "        # Clear GPU cache every 20 epochs\n",
        "        if device.type == 'cuda' and (epoch + 1) % 20 == 0:\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "    # Final results\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        # Final evaluation using best model (already saved in best_preds)\n",
        "        if best_preds is None:\n",
        "            # Re-evaluate if needed\n",
        "            out = model(data.x, data.edge_index, data.edge_attr)\n",
        "            best_preds = out.argmax(dim=1)\n",
        "            best_acc = (best_preds == data.y).float().mean().item()\n",
        "\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(f\"🏆 TRAINING COMPLETE\")\n",
        "    print(f\"Best Accuracy: {best_acc:.4f}\")\n",
        "    print(\"=\"*50 + \"\\n\")\n",
        "\n",
        "    # Detailed classification report\n",
        "    print(\"Classification Report:\")\n",
        "    print(classification_report(\n",
        "        data.y.cpu().numpy(),\n",
        "        best_preds.cpu().numpy(),\n",
        "        digits=4\n",
        "    ))\n",
        "\n",
        "    return best_acc, model\n",
        "\n",
        "# ============================================================\n",
        "# ✅ Memory Optimization Helper\n",
        "# ============================================================\n",
        "def optimize_memory_usage():\n",
        "    \"\"\"Helper function to optimize memory usage on Colab\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "        # Set memory fraction if needed\n",
        "        torch.cuda.set_per_process_memory_fraction(0.8)\n",
        "        print(\"✓ GPU memory optimized\")\n",
        "\n",
        "# ============================================================\n",
        "# ✅ Run Training\n",
        "# ============================================================\n",
        "# Optimize memory before starting\n",
        "optimize_memory_usage()\n",
        "\n",
        "# Train the model\n",
        "best_acc, trained_model = train_and_evaluate_optimized(data)\n",
        "\n",
        "# Optional: Test different learning rates\n",
        "def test_learning_rates(data, lrs=[3e-4, 5e-4, 1e-3], epochs=200):\n",
        "    \"\"\"Test different learning rates quickly\"\"\"\n",
        "    results = []\n",
        "\n",
        "    for lr in lrs:\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"Testing LR = {lr}\")\n",
        "        print('='*60)\n",
        "\n",
        "        # Clear cache before each run\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "        best_acc, _ = train_and_evaluate_optimized(\n",
        "            data,\n",
        "            lr=lr,\n",
        "            epochs=epochs,\n",
        "            batch_size=20000  # Smaller batch for faster testing\n",
        "        )\n",
        "\n",
        "        results.append((lr, best_acc))\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"LEARNING RATE COMPARISON\")\n",
        "    print(\"=\"*60)\n",
        "    for lr, acc in results:\n",
        "        print(f\"LR={lr:.1e}: Best Accuracy = {acc:.4f}\")\n",
        "\n",
        "    return results\n",
        "\n",
        "# Uncomment to test learning rates\n",
        "# lr_results = test_learning_rates(data, lrs=[3e-4, 5e-4, 8e-4], epochs=150)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "GlZsvy5spp7i",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "GlZsvy5spp7i",
        "outputId": "a568b219-ad83-45ef-96c1-af7302f4ce0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ GPU memory optimized\n",
            "Training on cuda\n",
            "Training with lr=0.0004, epochs=300, hidden=96\n",
            "\n",
            "🔥 New Best Accuracy: 0.5991 at epoch 1\n",
            "🔥 New Best Accuracy: 0.6178 at epoch 2\n",
            "🔥 New Best Accuracy: 0.6667 at epoch 3\n",
            "🔥 New Best Accuracy: 0.7026 at epoch 9\n",
            "Epoch [ 10/300] | Loss: 0.6079 | Train Acc: 0.6587 | Val Acc: 0.6629 | LR: 3.99e-04\n",
            "🔥 New Best Accuracy: 0.7700 at epoch 14\n",
            "🔥 New Best Accuracy: 0.7922 at epoch 17\n",
            "🔥 New Best Accuracy: 0.7950 at epoch 18\n",
            "Epoch [ 20/300] | Loss: 0.5278 | Train Acc: 0.7592 | Val Acc: 0.6931 | LR: 3.96e-04\n",
            "🔥 New Best Accuracy: 0.7999 at epoch 26\n",
            "🔥 New Best Accuracy: 0.8006 at epoch 27\n",
            "🔥 New Best Accuracy: 0.8031 at epoch 28\n",
            "Epoch [ 30/300] | Loss: 0.5449 | Train Acc: 0.7490 | Val Acc: 0.7984 | LR: 3.90e-04\n",
            "🔥 New Best Accuracy: 0.8098 at epoch 33\n",
            "🔥 New Best Accuracy: 0.8264 at epoch 38\n",
            "Epoch [ 40/300] | Loss: 0.5027 | Train Acc: 0.7864 | Val Acc: 0.7296 | LR: 3.83e-04\n",
            "Epoch [ 50/300] | Loss: 0.5040 | Train Acc: 0.7716 | Val Acc: 0.8111 | LR: 3.73e-04\n",
            "🔥 New Best Accuracy: 0.8346 at epoch 52\n",
            "🔥 New Best Accuracy: 0.8366 at epoch 53\n",
            "🔥 New Best Accuracy: 0.8404 at epoch 56\n",
            "Epoch [ 60/300] | Loss: 0.5018 | Train Acc: 0.7805 | Val Acc: 0.8131 | LR: 3.62e-04\n",
            "Epoch [ 70/300] | Loss: 0.4916 | Train Acc: 0.7730 | Val Acc: 0.7256 | LR: 3.49e-04\n",
            "Epoch [ 80/300] | Loss: 0.4992 | Train Acc: 0.7611 | Val Acc: 0.7261 | LR: 3.34e-04\n",
            "Epoch [ 90/300] | Loss: 0.4617 | Train Acc: 0.8000 | Val Acc: 0.8260 | LR: 3.18e-04\n",
            "Epoch [100/300] | Loss: 0.4678 | Train Acc: 0.8018 | Val Acc: 0.8127 | LR: 3.01e-04\n",
            "🔥 New Best Accuracy: 0.8423 at epoch 104\n",
            "Epoch [110/300] | Loss: 0.4556 | Train Acc: 0.8036 | Val Acc: 0.7262 | LR: 2.83e-04\n",
            "Epoch [120/300] | Loss: 0.4666 | Train Acc: 0.7986 | Val Acc: 0.8070 | LR: 2.63e-04\n",
            "Epoch [130/300] | Loss: 0.4609 | Train Acc: 0.7961 | Val Acc: 0.8096 | LR: 2.43e-04\n",
            "Epoch [140/300] | Loss: 0.4430 | Train Acc: 0.8140 | Val Acc: 0.7842 | LR: 2.23e-04\n",
            "Epoch [150/300] | Loss: 0.4615 | Train Acc: 0.7797 | Val Acc: 0.8219 | LR: 2.02e-04\n",
            "🔥 New Best Accuracy: 0.8577 at epoch 159\n",
            "Epoch [160/300] | Loss: 0.4412 | Train Acc: 0.8199 | Val Acc: 0.8320 | LR: 1.81e-04\n",
            "Epoch [170/300] | Loss: 0.4348 | Train Acc: 0.8278 | Val Acc: 0.8175 | LR: 1.61e-04\n",
            "Epoch [180/300] | Loss: 0.4353 | Train Acc: 0.8249 | Val Acc: 0.8460 | LR: 1.41e-04\n",
            "Epoch [190/300] | Loss: 0.4575 | Train Acc: 0.7820 | Val Acc: 0.8179 | LR: 1.21e-04\n",
            "Epoch [200/300] | Loss: 0.4384 | Train Acc: 0.8194 | Val Acc: 0.7854 | LR: 1.03e-04\n",
            "Epoch [210/300] | Loss: 0.4430 | Train Acc: 0.8063 | Val Acc: 0.7266 | LR: 8.56e-05\n",
            "Epoch [220/300] | Loss: 0.4261 | Train Acc: 0.8299 | Val Acc: 0.7602 | LR: 6.95e-05\n",
            "Epoch [230/300] | Loss: 0.4272 | Train Acc: 0.8305 | Val Acc: 0.8201 | LR: 5.49e-05\n",
            "Epoch [240/300] | Loss: 0.4309 | Train Acc: 0.8257 | Val Acc: 0.7599 | LR: 4.18e-05\n",
            "Epoch [250/300] | Loss: 0.4240 | Train Acc: 0.8321 | Val Acc: 0.7588 | LR: 3.05e-05\n",
            "Epoch [260/300] | Loss: 0.4226 | Train Acc: 0.8334 | Val Acc: 0.7591 | LR: 2.11e-05\n",
            "Epoch [270/300] | Loss: 0.4187 | Train Acc: 0.8364 | Val Acc: 0.7881 | LR: 1.37e-05\n",
            "Epoch [280/300] | Loss: 0.4202 | Train Acc: 0.8335 | Val Acc: 0.8198 | LR: 8.33e-06\n",
            "Epoch [290/300] | Loss: 0.4189 | Train Acc: 0.8338 | Val Acc: 0.7862 | LR: 5.08e-06\n",
            "Epoch [300/300] | Loss: 0.4190 | Train Acc: 0.8348 | Val Acc: 0.7582 | LR: 4.00e-06\n",
            "\n",
            "==================================================\n",
            "🏆 TRAINING COMPLETE\n",
            "Best Accuracy: 0.8577\n",
            "==================================================\n",
            "\n",
            "Classification Report:\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Found input variables with inconsistent numbers of samples: [200000, 50000]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2171096355.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m \u001b[0mbest_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrained_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_and_evaluate_optimized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[0;31m# Optional: Test different learning rates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2171096355.py\u001b[0m in \u001b[0;36mtrain_and_evaluate_optimized\u001b[0;34m(data, lr, epochs, batch_size)\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[0;31m# Detailed classification report\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Classification Report:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m     print(classification_report(\n\u001b[0m\u001b[1;32m    283\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0mbest_preds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                     )\n\u001b[1;32m    215\u001b[0m                 ):\n\u001b[0;32m--> 216\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[1;32m   2669\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2670\u001b[0m     \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattach_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2671\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2673\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \"\"\"\n\u001b[1;32m     97\u001b[0m     \u001b[0mxp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_namespace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y_true\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y_pred\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    476\u001b[0m             \u001b[0;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0;34m%\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [200000, 50000]"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import NNConv, LayerNorm\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "\n",
        "# Clear GPU cache at start\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# ============================================================\n",
        "# ✅ Enhanced Feature Normalization\n",
        "# ============================================================\n",
        "def normalize_features(data):\n",
        "    \"\"\"Normalize node and edge features\"\"\"\n",
        "    device = data.x.device\n",
        "\n",
        "    # Normalize edge features\n",
        "    if data.edge_attr is not None:\n",
        "        edge_attr_np = data.edge_attr.cpu().numpy()\n",
        "        if edge_attr_np.size > 0:\n",
        "            s_edge = StandardScaler()\n",
        "            edge_attr_np = s_edge.fit_transform(edge_attr_np)\n",
        "            edge_attr_np = np.nan_to_num(edge_attr_np, nan=0.0)\n",
        "            data.edge_attr = torch.tensor(edge_attr_np, dtype=torch.float, device=device)\n",
        "\n",
        "    # Normalize node features\n",
        "    if data.x is not None:\n",
        "        x_np = data.x.cpu().numpy()\n",
        "        if x_np.size > 0:\n",
        "            s_x = StandardScaler()\n",
        "            x_np = s_x.fit_transform(x_np)\n",
        "            x_np = np.nan_to_num(x_np, nan=0.0)\n",
        "            data.x = torch.tensor(x_np, dtype=torch.float, device=device)\n",
        "\n",
        "    return data\n",
        "\n",
        "# Apply normalization\n",
        "data = normalize_features(data)\n",
        "\n",
        "# ============================================================\n",
        "# ✅ Optimized EdgeGNN with Hidden Layers = 128\n",
        "# ============================================================\n",
        "class OptimizedEdgeGNN(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, dropout=0.4):\n",
        "        super().__init__()\n",
        "        self.hidden_channels = 128  # Fixed as requested\n",
        "\n",
        "        # Edge feature networks (optimized)\n",
        "        self.edge_net1 = nn.Sequential(\n",
        "            nn.Linear(data.edge_attr.shape[1], 64),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout * 0.3),\n",
        "            nn.Linear(64, in_channels * self.hidden_channels)\n",
        "        )\n",
        "\n",
        "        self.edge_net2 = nn.Sequential(\n",
        "            nn.Linear(data.edge_attr.shape[1], 64),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout * 0.3),\n",
        "            nn.Linear(64, self.hidden_channels * self.hidden_channels)\n",
        "        )\n",
        "\n",
        "        # Convolution layers\n",
        "        self.conv1 = NNConv(in_channels, self.hidden_channels, self.edge_net1, aggr='mean')\n",
        "        self.conv2 = NNConv(self.hidden_channels, self.hidden_channels, self.edge_net2, aggr='mean')\n",
        "\n",
        "        # Normalization layers (LayerNorm is more memory efficient)\n",
        "        self.norm1 = LayerNorm(self.hidden_channels)\n",
        "        self.norm2 = LayerNorm(self.hidden_channels)\n",
        "\n",
        "        # Skip connection projection\n",
        "        self.skip_proj = nn.Linear(in_channels, self.hidden_channels)\n",
        "\n",
        "        # Output layers\n",
        "        self.output_mlp = nn.Sequential(\n",
        "            nn.Linear(self.hidden_channels, 48),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.LayerNorm(48),\n",
        "            nn.Linear(48, out_channels)\n",
        "        )\n",
        "\n",
        "        # Initialize weights properly\n",
        "        self._init_weights()\n",
        "\n",
        "    def _init_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_in', nonlinearity='relu')\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def forward(self, x, edge_index, edge_attr):\n",
        "        # First convolution with residual connection\n",
        "        identity = self.skip_proj(x)\n",
        "        x1 = self.conv1(x, edge_index, edge_attr)\n",
        "        x1 = self.norm1(x1)\n",
        "        x1 = F.gelu(x1 + identity)  # Residual connection\n",
        "\n",
        "        # Second convolution\n",
        "        x2 = self.conv2(x1, edge_index, edge_attr)\n",
        "        x2 = self.norm2(x2)\n",
        "        x2 = F.gelu(x2)\n",
        "\n",
        "        # Apply dropout\n",
        "        x2 = F.dropout(x2, p=0.4, training=self.training)\n",
        "\n",
        "        # Get edge source node features and apply output MLP\n",
        "        edge_sources = x2[edge_index[0]]\n",
        "        return self.output_mlp(edge_sources)\n",
        "\n",
        "# ============================================================\n",
        "# ✅ Training Function (No Early Stopping)\n",
        "# ============================================================\n",
        "def train_and_evaluate_optimized(data, lr=4e-4, epochs=300, batch_size=25000):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Training on {device}\")\n",
        "\n",
        "    # Create model with fixed 96 hidden channels\n",
        "    model = OptimizedEdgeGNN(\n",
        "        in_channels=data.x.shape[1],\n",
        "        out_channels=2,\n",
        "        dropout=0.4\n",
        "    ).to(device)\n",
        "\n",
        "    # Optimizer with weight decay\n",
        "    optimizer = torch.optim.AdamW(\n",
        "        model.parameters(),\n",
        "        lr=lr,\n",
        "        weight_decay=1e-4,\n",
        "        betas=(0.9, 0.99)\n",
        "    )\n",
        "\n",
        "    # Cosine annealing scheduler\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
        "        optimizer,\n",
        "        T_max=epochs,\n",
        "        eta_min=lr * 0.01\n",
        "    )\n",
        "\n",
        "    # Label smoothing for better generalization\n",
        "    criterion = nn.CrossEntropyLoss(label_smoothing=0.05)\n",
        "\n",
        "    num_edges = data.edge_index.shape[1]\n",
        "    best_acc = 0.0\n",
        "    best_preds = None\n",
        "\n",
        "    print(f\"Training with lr={lr}, epochs={epochs}, hidden=96\\n\")\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        total_correct = 0\n",
        "        total_samples = 0\n",
        "\n",
        "        # Use batch training for memory efficiency\n",
        "        if batch_size and batch_size < num_edges:\n",
        "            # Shuffle edges for each epoch\n",
        "            indices = torch.randperm(num_edges, device=device)\n",
        "\n",
        "            for start in range(0, num_edges, batch_size):\n",
        "                end = min(start + batch_size, num_edges)\n",
        "                batch_idx = indices[start:end]\n",
        "\n",
        "                optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "                # Get batch data\n",
        "                edge_index_batch = data.edge_index[:, batch_idx]\n",
        "                edge_attr_batch = data.edge_attr[batch_idx]\n",
        "                labels_batch = data.y[batch_idx]\n",
        "\n",
        "                # Forward pass\n",
        "                out = model(data.x, edge_index_batch, edge_attr_batch)\n",
        "\n",
        "                # Skip if NaN\n",
        "                if torch.isnan(out).any():\n",
        "                    continue\n",
        "\n",
        "                # Loss calculation\n",
        "                loss = criterion(out, labels_batch)\n",
        "\n",
        "                # Backward pass with gradient accumulation\n",
        "                loss.backward()\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "                optimizer.step()\n",
        "                optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "                # Track metrics\n",
        "                total_loss += loss.item() * len(labels_batch)\n",
        "                preds = out.argmax(dim=1)\n",
        "                total_correct += (preds == labels_batch).sum().item()\n",
        "                total_samples += len(labels_batch)\n",
        "        else:\n",
        "            # Full batch training\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "            out = model(data.x, data.edge_index, data.edge_attr)\n",
        "\n",
        "            if torch.isnan(out).any():\n",
        "                print(\"⚠️ NaN detected. Skipping epoch.\")\n",
        "                continue\n",
        "\n",
        "            loss = criterion(out, data.y)\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss = loss.item() * num_edges\n",
        "            preds = out.argmax(dim=1)\n",
        "            total_correct = (preds == data.y).sum().item()\n",
        "            total_samples = num_edges\n",
        "\n",
        "        # Update learning rate\n",
        "        scheduler.step()\n",
        "\n",
        "        # Evaluation\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            # Use small batches for evaluation to save memory\n",
        "            eval_acc = 0\n",
        "            eval_samples = 0\n",
        "\n",
        "            if num_edges > 50000:  # Large graph, evaluate in batches\n",
        "                eval_batch_size = min(50000, num_edges)\n",
        "                for start in range(0, num_edges, eval_batch_size):\n",
        "                    end = min(start + eval_batch_size, num_edges)\n",
        "                    edge_index_batch = data.edge_index[:, start:end]\n",
        "                    edge_attr_batch = data.edge_attr[start:end]\n",
        "                    labels_batch = data.y[start:end]\n",
        "\n",
        "                    out = model(data.x, edge_index_batch, edge_attr_batch)\n",
        "                    preds = out.argmax(dim=1)\n",
        "                    eval_acc += (preds == labels_batch).sum().item()\n",
        "                    eval_samples += len(labels_batch)\n",
        "\n",
        "                acc = eval_acc / eval_samples\n",
        "            else:\n",
        "                # Full evaluation for smaller graphs\n",
        "                out = model(data.x, data.edge_index, data.edge_attr)\n",
        "                preds = out.argmax(dim=1)\n",
        "                acc = (preds == data.y).float().mean().item()\n",
        "\n",
        "        # Track best accuracy\n",
        "        if acc > best_acc:\n",
        "            best_acc = acc\n",
        "            best_preds = preds.clone()\n",
        "            print(f\"🔥 New Best Accuracy: {best_acc:.4f} at epoch {epoch+1}\")\n",
        "\n",
        "        # Print progress every 10 epochs\n",
        "        if (epoch + 1) % 10 == 0:\n",
        "            avg_loss = total_loss / total_samples if total_samples > 0 else 0\n",
        "            train_acc = total_correct / total_samples if total_samples > 0 else 0\n",
        "            current_lr = optimizer.param_groups[0]['lr']\n",
        "            print(f\"Epoch [{epoch+1:3d}/{epochs}] | \"\n",
        "                  f\"Loss: {avg_loss:.4f} | \"\n",
        "                  f\"Train Acc: {train_acc:.4f} | \"\n",
        "                  f\"Val Acc: {acc:.4f} | \"\n",
        "                  f\"LR: {current_lr:.2e}\")\n",
        "\n",
        "        # Clear GPU cache every 20 epochs\n",
        "        if device.type == 'cuda' and (epoch + 1) % 20 == 0:\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "    # Final results\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        # Final evaluation using best model (already saved in best_preds)\n",
        "        if best_preds is None:\n",
        "            # Re-evaluate if needed\n",
        "            out = model(data.x, data.edge_index, data.edge_attr)\n",
        "            best_preds = out.argmax(dim=1)\n",
        "            best_acc = (best_preds == data.y).float().mean().item()\n",
        "\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(f\"🏆 TRAINING COMPLETE\")\n",
        "    print(f\"Best Accuracy: {best_acc:.4f}\")\n",
        "    print(\"=\"*50 + \"\\n\")\n",
        "\n",
        "    # Detailed classification report\n",
        "    print(\"Classification Report:\")\n",
        "    print(classification_report(\n",
        "        data.y.cpu().numpy(),\n",
        "        best_preds.cpu().numpy(),\n",
        "        digits=4\n",
        "    ))\n",
        "\n",
        "    return best_acc, model\n",
        "\n",
        "# ============================================================\n",
        "# ✅ Memory Optimization Helper\n",
        "# ============================================================\n",
        "def optimize_memory_usage():\n",
        "    \"\"\"Helper function to optimize memory usage on Colab\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "        # Set memory fraction if needed\n",
        "        torch.cuda.set_per_process_memory_fraction(0.8)\n",
        "        print(\"✓ GPU memory optimized\")\n",
        "\n",
        "# ============================================================\n",
        "# ✅ Run Training\n",
        "# ============================================================\n",
        "# Optimize memory before starting\n",
        "optimize_memory_usage()\n",
        "\n",
        "# Train the model\n",
        "best_acc, trained_model = train_and_evaluate_optimized(data)\n",
        "\n",
        "# Optional: Test different learning rates\n",
        "def test_learning_rates(data, lrs=[3e-4, 5e-4, 1e-3], epochs=200):\n",
        "    \"\"\"Test different learning rates quickly\"\"\"\n",
        "    results = []\n",
        "\n",
        "    for lr in lrs:\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"Testing LR = {lr}\")\n",
        "        print('='*60)\n",
        "\n",
        "        # Clear cache before each run\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "        best_acc, _ = train_and_evaluate_optimized(\n",
        "            data,\n",
        "            lr=lr,\n",
        "            epochs=epochs,\n",
        "            batch_size=20000  # Smaller batch for faster testing\n",
        "        )\n",
        "\n",
        "        results.append((lr, best_acc))\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"LEARNING RATE COMPARISON\")\n",
        "    print(\"=\"*60)\n",
        "    for lr, acc in results:\n",
        "        print(f\"LR={lr:.1e}: Best Accuracy = {acc:.4f}\")\n",
        "\n",
        "    return results\n",
        "\n",
        "# Uncomment to test learning rates\n",
        "# lr_results = test_learning_rates(data, lrs=[3e-4, 5e-4, 8e-4], epochs=150)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "7htujNsWuVX-",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        },
        "id": "7htujNsWuVX-",
        "outputId": "11ff9aeb-e970-493b-ff65-d44dda18397d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Memory optimized\n",
            "Training single advanced model...\n",
            "Training on cuda\n",
            "Model parameters: 1,286,596\n",
            "Total edges: 200,000\n",
            "Training with lr=0.0003, epochs=400, hidden=128\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "mat1 and mat2 shapes cannot be multiplied (30000x256 and 128x128)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4114214270.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;31m# Option 1: Train single model (for Colab memory constraints)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training single advanced model...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m \u001b[0mbest_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_f1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_and_evaluate_advanced\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[0;31m# Option 2: Train ensemble (for best accuracy, but uses more memory)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-4114214270.py\u001b[0m in \u001b[0;36mtrain_and_evaluate_advanced\u001b[0;34m(data, lr, epochs, batch_size)\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m             \u001b[0;31m# Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_attr_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[0;31m# Skip if NaN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-4114214270.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, edge_attr)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;31m# Final classification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_mlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;31m# ============================================================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \"\"\"\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0mRuns\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mforward\u001b[0m \u001b[0;32mpass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \"\"\"\n\u001b[0;32m--> 134\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (30000x256 and 128x128)"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import NNConv, LayerNorm, GATConv, GINEConv\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, f1_score\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Clear GPU cache at start\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# ============================================================\n",
        "# ✅ Enhanced Feature Normalization with Graph-aware features\n",
        "# ============================================================\n",
        "def normalize_features_with_graph(data):\n",
        "    \"\"\"Normalize features and add graph structural features\"\"\"\n",
        "    device = data.x.device\n",
        "\n",
        "    # Normalize edge features\n",
        "    if data.edge_attr is not None:\n",
        "        edge_attr_np = data.edge_attr.cpu().numpy()\n",
        "        if edge_attr_np.size > 0:\n",
        "            s_edge = StandardScaler()\n",
        "            edge_attr_np = s_edge.fit_transform(edge_attr_np)\n",
        "            edge_attr_np = np.nan_to_num(edge_attr_np, nan=0.0)\n",
        "            data.edge_attr = torch.tensor(edge_attr_np, dtype=torch.float, device=device)\n",
        "\n",
        "    # Normalize node features\n",
        "    if data.x is not None:\n",
        "        x_np = data.x.cpu().numpy()\n",
        "        if x_np.size > 0:\n",
        "            s_x = StandardScaler()\n",
        "            x_np = s_x.fit_transform(x_np)\n",
        "            x_np = np.nan_to_num(x_np, nan=0.0)\n",
        "            data.x = torch.tensor(x_np, dtype=torch.float, device=device)\n",
        "\n",
        "    # Add degree features (important for graph structure)\n",
        "    from torch_geometric.utils import degree\n",
        "    deg = degree(data.edge_index[0], num_nodes=data.num_nodes, dtype=torch.float)\n",
        "    deg_norm = (deg - deg.mean()) / (deg.std() + 1e-6)\n",
        "    data.x = torch.cat([data.x, deg_norm.unsqueeze(1)], dim=1)\n",
        "\n",
        "    return data\n",
        "\n",
        "# Apply enhanced normalization\n",
        "data = normalize_features_with_graph(data)\n",
        "\n",
        "# ============================================================\n",
        "# ✅ Advanced EdgeGNN with Multiple Improvements\n",
        "# ============================================================\n",
        "class AdvancedEdgeGNN(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, dropout=0.4):\n",
        "        super().__init__()\n",
        "        self.hidden_channels = 128\n",
        "\n",
        "        # Edge feature networks with skip connections\n",
        "        self.edge_net1 = nn.Sequential(\n",
        "            nn.Linear(data.edge_attr.shape[1], 128),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout * 0.2),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(64, in_channels * self.hidden_channels)\n",
        "        )\n",
        "\n",
        "        self.edge_net2 = nn.Sequential(\n",
        "            nn.Linear(data.edge_attr.shape[1], 128),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout * 0.2),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(64, self.hidden_channels * self.hidden_channels)\n",
        "        )\n",
        "\n",
        "        # First GNN layer\n",
        "        self.conv1 = NNConv(in_channels, self.hidden_channels, self.edge_net1, aggr='mean')\n",
        "        self.norm1 = LayerNorm(self.hidden_channels)\n",
        "\n",
        "        # Second GNN layer (try GAT for attention)\n",
        "        self.conv2 = GATConv(\n",
        "            self.hidden_channels, self.hidden_channels // 2, heads=2,\n",
        "            dropout=dropout, concat=True, edge_dim=data.edge_attr.shape[1]\n",
        "        )\n",
        "        self.norm2 = LayerNorm(self.hidden_channels)  # 2 * hidden_channels//2 = hidden_channels\n",
        "\n",
        "        # Third GNN layer (GINE for better edge feature handling)\n",
        "        edge_mlp = nn.Sequential(\n",
        "            nn.Linear(data.edge_attr.shape[1], 64),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(64, self.hidden_channels)\n",
        "        )\n",
        "        self.conv3 = GINEConv(\n",
        "            nn.Sequential(\n",
        "                nn.Linear(self.hidden_channels, self.hidden_channels * 2),\n",
        "                nn.GELU(),\n",
        "                nn.Dropout(dropout * 0.3),\n",
        "                nn.Linear(self.hidden_channels * 2, self.hidden_channels)\n",
        "            ),\n",
        "            edge_dim=data.edge_attr.shape[1],\n",
        "            train_eps=True\n",
        "        )\n",
        "        self.norm3 = LayerNorm(self.hidden_channels)\n",
        "\n",
        "        # Skip connection projections\n",
        "        self.skip1 = nn.Linear(in_channels, self.hidden_channels)\n",
        "        self.skip2 = nn.Linear(self.hidden_channels, self.hidden_channels)\n",
        "\n",
        "        # Advanced output MLP with residual connections\n",
        "        self.output_mlp = nn.Sequential(\n",
        "            nn.Linear(self.hidden_channels, self.hidden_channels),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout * 0.5),\n",
        "            nn.LayerNorm(self.hidden_channels),\n",
        "\n",
        "            nn.Linear(self.hidden_channels, self.hidden_channels // 2),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout * 0.3),\n",
        "            nn.LayerNorm(self.hidden_channels // 2),\n",
        "\n",
        "            nn.Linear(self.hidden_channels // 2, out_channels)\n",
        "        )\n",
        "\n",
        "        # Attention pooling for edge classification\n",
        "        self.edge_attention = nn.Sequential(\n",
        "            nn.Linear(self.hidden_channels * 2, 64),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(64, 1)\n",
        "        )\n",
        "\n",
        "        self._init_weights()\n",
        "\n",
        "    def _init_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.xavier_uniform_(m.weight)\n",
        "                if m.bias is not None:\n",
        "                    nn.init.zeros_(m.bias)\n",
        "\n",
        "    def forward(self, x, edge_index, edge_attr):\n",
        "        # Layer 1: NNConv with residual\n",
        "        identity1 = self.skip1(x)\n",
        "        x1 = self.conv1(x, edge_index, edge_attr)\n",
        "        x1 = self.norm1(x1)\n",
        "        x1 = F.gelu(x1 + identity1)\n",
        "        x1 = F.dropout(x1, p=0.3, training=self.training)\n",
        "\n",
        "        # Layer 2: GAT with attention\n",
        "        x2 = self.conv2(x1, edge_index, edge_attr)\n",
        "        x2 = self.norm2(x2)\n",
        "        x2 = F.gelu(x2)\n",
        "        x2 = F.dropout(x2, p=0.3, training=self.training)\n",
        "\n",
        "        # Layer 3: GINE with edge features\n",
        "        identity2 = self.skip2(x2)\n",
        "        x3 = self.conv3(x2, edge_index, edge_attr)\n",
        "        x3 = self.norm3(x3)\n",
        "        x3 = F.gelu(x3 + identity2)\n",
        "        x3 = F.dropout(x3, p=0.4, training=self.training)\n",
        "\n",
        "        # Get source and target node features for edges\n",
        "        edge_sources = x3[edge_index[0]]\n",
        "        edge_targets = x3[edge_index[1]]\n",
        "\n",
        "        # Combine source and target features\n",
        "        edge_features = torch.cat([edge_sources, edge_targets], dim=1)\n",
        "\n",
        "        # Apply attention to edge features\n",
        "        attention_weights = torch.sigmoid(self.edge_attention(edge_features))\n",
        "        edge_features = edge_features * attention_weights\n",
        "\n",
        "        # Final classification\n",
        "        return self.output_mlp(edge_features)\n",
        "\n",
        "# ============================================================\n",
        "# ✅ Improved Training Function with Fix for Prediction Mismatch\n",
        "# ============================================================\n",
        "def train_and_evaluate_advanced(data, lr=3e-4, epochs=400, batch_size=30000):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Training on {device}\")\n",
        "\n",
        "    # Create advanced model\n",
        "    model = AdvancedEdgeGNN(\n",
        "        in_channels=data.x.shape[1],\n",
        "        out_channels=2,\n",
        "        dropout=0.4\n",
        "    ).to(device)\n",
        "\n",
        "    print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
        "\n",
        "    # Optimizer with different settings for different components\n",
        "    param_groups = [\n",
        "        {'params': model.conv1.parameters(), 'lr': lr * 0.8},\n",
        "        {'params': model.conv2.parameters(), 'lr': lr},\n",
        "        {'params': model.conv3.parameters(), 'lr': lr * 1.2},\n",
        "        {'params': model.output_mlp.parameters(), 'lr': lr},\n",
        "        {'params': model.edge_attention.parameters(), 'lr': lr * 0.5},\n",
        "    ]\n",
        "\n",
        "    optimizer = torch.optim.AdamW(\n",
        "        param_groups,\n",
        "        weight_decay=1e-4,\n",
        "        betas=(0.9, 0.99)\n",
        "    )\n",
        "\n",
        "    # Multi-step learning rate scheduler\n",
        "    scheduler = torch.optim.lr_scheduler.MultiStepLR(\n",
        "        optimizer,\n",
        "        milestones=[100, 200, 300],\n",
        "        gamma=0.5\n",
        "    )\n",
        "\n",
        "    # Focal loss for handling class imbalance\n",
        "    class FocalLoss(nn.Module):\n",
        "        def __init__(self, alpha=0.25, gamma=2.0):\n",
        "            super().__init__()\n",
        "            self.alpha = alpha\n",
        "            self.gamma = gamma\n",
        "\n",
        "        def forward(self, inputs, targets):\n",
        "            ce_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
        "            pt = torch.exp(-ce_loss)\n",
        "            focal_loss = self.alpha * (1-pt)**self.gamma * ce_loss\n",
        "            return focal_loss.mean()\n",
        "\n",
        "    criterion = FocalLoss(alpha=0.25, gamma=2.0)\n",
        "\n",
        "    num_edges = data.edge_index.shape[1]\n",
        "    best_acc = 0.0\n",
        "    best_f1 = 0.0\n",
        "    best_preds = None\n",
        "\n",
        "    print(f\"Total edges: {num_edges:,}\")\n",
        "    print(f\"Training with lr={lr}, epochs={epochs}, hidden=128\\n\")\n",
        "\n",
        "    # Training history\n",
        "    history = {'loss': [], 'acc': [], 'f1': []}\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        total_correct = 0\n",
        "        total_samples = 0\n",
        "\n",
        "        # Shuffle edges for each epoch\n",
        "        indices = torch.randperm(num_edges, device=device)\n",
        "\n",
        "        for start in range(0, num_edges, batch_size):\n",
        "            end = min(start + batch_size, num_edges)\n",
        "            batch_idx = indices[start:end]\n",
        "\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "            # Get batch data\n",
        "            edge_index_batch = data.edge_index[:, batch_idx]\n",
        "            edge_attr_batch = data.edge_attr[batch_idx]\n",
        "            labels_batch = data.y[batch_idx]\n",
        "\n",
        "            # Forward pass\n",
        "            out = model(data.x, edge_index_batch, edge_attr_batch)\n",
        "\n",
        "            # Skip if NaN\n",
        "            if torch.isnan(out).any():\n",
        "                continue\n",
        "\n",
        "            # Loss calculation\n",
        "            loss = criterion(out, labels_batch)\n",
        "\n",
        "            # Gradient clipping\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "            optimizer.step()\n",
        "\n",
        "            # Track metrics\n",
        "            total_loss += loss.item() * len(labels_batch)\n",
        "            preds = out.argmax(dim=1)\n",
        "            total_correct += (preds == labels_batch).sum().item()\n",
        "            total_samples += len(labels_batch)\n",
        "\n",
        "        # Update learning rate\n",
        "        scheduler.step()\n",
        "\n",
        "        # Evaluation on full dataset (in batches to avoid OOM)\n",
        "        model.eval()\n",
        "        all_preds = []\n",
        "        all_labels = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            eval_batch_size = min(50000, num_edges)\n",
        "            for start in range(0, num_edges, eval_batch_size):\n",
        "                end = min(start + eval_batch_size, num_edges)\n",
        "                edge_index_batch = data.edge_index[:, start:end]\n",
        "                edge_attr_batch = data.edge_attr[start:end]\n",
        "                labels_batch = data.y[start:end]\n",
        "\n",
        "                out = model(data.x, edge_index_batch, edge_attr_batch)\n",
        "                preds = out.argmax(dim=1)\n",
        "\n",
        "                all_preds.append(preds.cpu())\n",
        "                all_labels.append(labels_batch.cpu())\n",
        "\n",
        "        # Concatenate all predictions\n",
        "        all_preds = torch.cat(all_preds, dim=0)\n",
        "        all_labels = torch.cat(all_labels, dim=0)\n",
        "\n",
        "        # Calculate metrics\n",
        "        acc = (all_preds == all_labels).float().mean().item()\n",
        "        f1 = f1_score(all_labels.numpy(), all_preds.numpy(), average='weighted')\n",
        "\n",
        "        # Track best model\n",
        "        if acc > best_acc or (abs(acc - best_acc) < 0.001 and f1 > best_f1):\n",
        "            best_acc = acc\n",
        "            best_f1 = f1\n",
        "            best_preds = all_preds.clone()\n",
        "            print(f\"🔥 New Best: Acc={best_acc:.4f}, F1={best_f1:.4f} at epoch {epoch+1}\")\n",
        "\n",
        "        # Store history\n",
        "        history['loss'].append(total_loss / total_samples if total_samples > 0 else 0)\n",
        "        history['acc'].append(acc)\n",
        "        history['f1'].append(f1)\n",
        "\n",
        "        # Print progress every 10 epochs\n",
        "        if (epoch + 1) % 10 == 0:\n",
        "            avg_loss = total_loss / total_samples if total_samples > 0 else 0\n",
        "            train_acc = total_correct / total_samples if total_samples > 0 else 0\n",
        "            current_lr = optimizer.param_groups[0]['lr']\n",
        "            print(f\"Epoch [{epoch+1:3d}/{epochs}] | \"\n",
        "                  f\"Loss: {avg_loss:.4f} | \"\n",
        "                  f\"Train Acc: {train_acc:.4f} | \"\n",
        "                  f\"Val Acc: {acc:.4f} | \"\n",
        "                  f\"F1: {f1:.4f} | \"\n",
        "                  f\"LR: {current_lr:.2e}\")\n",
        "\n",
        "        # Clear GPU cache every 25 epochs\n",
        "        if device.type == 'cuda' and (epoch + 1) % 25 == 0:\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "    # Final evaluation\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"FINAL RESULTS\")\n",
        "    print(\"=\"*60)\n",
        "    print(f\"Best Accuracy: {best_acc:.4f}\")\n",
        "    print(f\"Best F1 Score: {best_f1:.4f}\")\n",
        "\n",
        "    # Classification report\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(\n",
        "        data.y.cpu().numpy(),\n",
        "        best_preds.numpy(),\n",
        "        digits=4,\n",
        "        target_names=['Class 0', 'Class 1']\n",
        "    ))\n",
        "\n",
        "    # Confusion matrix (optional)\n",
        "    from sklearn.metrics import confusion_matrix\n",
        "    cm = confusion_matrix(data.y.cpu().numpy(), best_preds.numpy())\n",
        "    print(f\"Confusion Matrix:\\n{cm}\")\n",
        "\n",
        "    # Calculate per-class accuracy\n",
        "    class_0_acc = cm[0,0] / cm[0].sum() if cm[0].sum() > 0 else 0\n",
        "    class_1_acc = cm[1,1] / cm[1].sum() if cm[1].sum() > 0 else 0\n",
        "    print(f\"\\nClass 0 Accuracy: {class_0_acc:.4f}\")\n",
        "    print(f\"Class 1 Accuracy: {class_1_acc:.4f}\")\n",
        "\n",
        "    return best_acc, best_f1, model, history\n",
        "\n",
        "# ============================================================\n",
        "# ✅ Ensemble Training for Better Accuracy\n",
        "# ============================================================\n",
        "def train_ensemble(data, n_models=3, epochs=300):\n",
        "    \"\"\"Train an ensemble of models for better accuracy\"\"\"\n",
        "    print(f\"Training ensemble of {n_models} models...\")\n",
        "\n",
        "    models = []\n",
        "    predictions = []\n",
        "\n",
        "    for i in range(n_models):\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"Training model {i+1}/{n_models}\")\n",
        "        print('='*60)\n",
        "\n",
        "        # Use different learning rates for each model\n",
        "        lr = 3e-4 * (0.8 + 0.4 * i / n_models)  # Vary LR slightly\n",
        "\n",
        "        # Train model\n",
        "        best_acc, best_f1, model, _ = train_and_evaluate_advanced(\n",
        "            data,\n",
        "            lr=lr,\n",
        "            epochs=epochs,\n",
        "            batch_size=30000\n",
        "        )\n",
        "\n",
        "        models.append(model)\n",
        "\n",
        "        # Get predictions from this model\n",
        "        model.eval()\n",
        "        all_preds = []\n",
        "        num_edges = data.edge_index.shape[1]\n",
        "\n",
        "        with torch.no_grad():\n",
        "            eval_batch_size = min(50000, num_edges)\n",
        "            for start in range(0, num_edges, eval_batch_size):\n",
        "                end = min(start + eval_batch_size, num_edges)\n",
        "                edge_index_batch = data.edge_index[:, start:end]\n",
        "                edge_attr_batch = data.edge_attr[start:end]\n",
        "\n",
        "                out = model(data.x, edge_index_batch, edge_attr_batch)\n",
        "                preds = F.softmax(out, dim=1)\n",
        "                all_preds.append(preds.cpu())\n",
        "\n",
        "        predictions.append(torch.cat(all_preds, dim=0))\n",
        "\n",
        "    # Ensemble predictions (average probabilities)\n",
        "    ensemble_probs = sum(predictions) / n_models\n",
        "    ensemble_preds = ensemble_probs.argmax(dim=1)\n",
        "\n",
        "    # Calculate ensemble accuracy\n",
        "    ensemble_acc = (ensemble_preds == data.y.cpu()).float().mean().item()\n",
        "    ensemble_f1 = f1_score(data.y.cpu().numpy(), ensemble_preds.numpy(), average='weighted')\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\"ENSEMBLE RESULTS\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"Ensemble Accuracy: {ensemble_acc:.4f}\")\n",
        "    print(f\"Ensemble F1 Score: {ensemble_f1:.4f}\")\n",
        "\n",
        "    return ensemble_acc, ensemble_f1, models\n",
        "\n",
        "# ============================================================\n",
        "# ✅ Memory Optimization\n",
        "# ============================================================\n",
        "def optimize_memory():\n",
        "    \"\"\"Optimize memory usage\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "        torch.cuda.reset_peak_memory_stats()\n",
        "        print(\"✓ Memory optimized\")\n",
        "\n",
        "# ============================================================\n",
        "# ✅ Run Training\n",
        "# ============================================================\n",
        "# Optimize memory\n",
        "optimize_memory()\n",
        "\n",
        "# Option 1: Train single model (for Colab memory constraints)\n",
        "print(\"Training single advanced model...\")\n",
        "best_acc, best_f1, model, history = train_and_evaluate_advanced(data)\n",
        "\n",
        "# Option 2: Train ensemble (for best accuracy, but uses more memory)\n",
        "# Uncomment if you have enough memory\n",
        "# ensemble_acc, ensemble_f1, models = train_ensemble(data, n_models=3, epochs=250)\n",
        "\n",
        "# ============================================================\n",
        "# ✅ Post-training Analysis\n",
        "# ============================================================\n",
        "def analyze_results(data, model):\n",
        "    \"\"\"Analyze model predictions to identify difficult cases\"\"\"\n",
        "    model.eval()\n",
        "    num_edges = data.edge_index.shape[1]\n",
        "\n",
        "    # Get predictions and probabilities\n",
        "    all_preds = []\n",
        "    all_probs = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        eval_batch_size = min(50000, num_edges)\n",
        "        for start in range(0, num_edges, eval_batch_size):\n",
        "            end = min(start + eval_batch_size, num_edges)\n",
        "            edge_index_batch = data.edge_index[:, start:end]\n",
        "            edge_attr_batch = data.edge_attr[start:end]\n",
        "\n",
        "            out = model(data.x, edge_index_batch, edge_attr_batch)\n",
        "            probs = F.softmax(out, dim=1)\n",
        "            preds = probs.argmax(dim=1)\n",
        "\n",
        "            all_preds.append(preds.cpu())\n",
        "            all_probs.append(probs.cpu())\n",
        "\n",
        "    all_preds = torch.cat(all_preds, dim=0)\n",
        "    all_probs = torch.cat(all_probs, dim=0)\n",
        "\n",
        "    # Analyze confidence\n",
        "    confidence = all_probs.max(dim=1).values\n",
        "    print(f\"\\nAverage confidence: {confidence.mean():.4f}\")\n",
        "    print(f\"Low confidence samples (<0.7): {(confidence < 0.7).sum().item()}\")\n",
        "    print(f\"High confidence samples (>0.9): {(confidence > 0.9).sum().item()}\")\n",
        "\n",
        "    # Identify misclassified samples\n",
        "    misclassified = (all_preds != data.y.cpu())\n",
        "    if misclassified.sum() > 0:\n",
        "        misclassified_conf = confidence[misclassified]\n",
        "        print(f\"\\nMisclassified samples: {misclassified.sum().item()}\")\n",
        "        print(f\"Average confidence on misclassified: {misclassified_conf.mean():.4f}\")\n",
        "\n",
        "    return all_preds, all_probs\n",
        "\n",
        "# Run analysis\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"POST-TRAINING ANALYSIS\")\n",
        "print(\"=\"*60)\n",
        "preds, probs = analyze_results(data, model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "RSFBR3w-KtOn",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "RSFBR3w-KtOn",
        "outputId": "70c5f753-3fd6-4410-8d4d-419d814b76e8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-2317503036.py:179: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler()\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training EdgeGAT on cuda | edges=200000 | nodes=400000 | classes=2\n",
            "\n",
            "Epoch 001/200 | Loss: 0.702315 | Acc: 0.4990 | Macro-F1: 0.3369 | Best-Acc: 0.4990\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 010/200 | Loss: 0.699966 | Acc: 0.4987 | Macro-F1: 0.3372 | Best-Acc: 0.4990\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 020/200 | Loss: 0.692394 | Acc: 0.5271 | Macro-F1: 0.5263 | Best-Acc: 0.5271\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 030/200 | Loss: 0.682995 | Acc: 0.5427 | Macro-F1: 0.5392 | Best-Acc: 0.5427\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 040/200 | Loss: 0.673164 | Acc: 0.6457 | Macro-F1: 0.6312 | Best-Acc: 0.6457\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 050/200 | Loss: 0.661808 | Acc: 0.6583 | Macro-F1: 0.6442 | Best-Acc: 0.6583\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 060/200 | Loss: 0.650518 | Acc: 0.6672 | Macro-F1: 0.6522 | Best-Acc: 0.6672\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 070/200 | Loss: 0.638378 | Acc: 0.6692 | Macro-F1: 0.6551 | Best-Acc: 0.6692\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 080/200 | Loss: 0.626229 | Acc: 0.6696 | Macro-F1: 0.6564 | Best-Acc: 0.6701\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 090/200 | Loss: 0.613939 | Acc: 0.6650 | Macro-F1: 0.6534 | Best-Acc: 0.6701\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 100/200 | Loss: 0.603263 | Acc: 0.6697 | Macro-F1: 0.6592 | Best-Acc: 0.6701\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 110/200 | Loss: 0.593214 | Acc: 0.6796 | Macro-F1: 0.6703 | Best-Acc: 0.6796\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 120/200 | Loss: 0.584228 | Acc: 0.6858 | Macro-F1: 0.6774 | Best-Acc: 0.6858\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 130/200 | Loss: 0.577912 | Acc: 0.6981 | Macro-F1: 0.6914 | Best-Acc: 0.6981\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 140/200 | Loss: 0.572409 | Acc: 0.7045 | Macro-F1: 0.6986 | Best-Acc: 0.7049\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 150/200 | Loss: 0.568254 | Acc: 0.7066 | Macro-F1: 0.7006 | Best-Acc: 0.7067\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 160/200 | Loss: 0.564958 | Acc: 0.8200 | Macro-F1: 0.8169 | Best-Acc: 0.8280\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 170/200 | Loss: 0.563265 | Acc: 0.8041 | Macro-F1: 0.7996 | Best-Acc: 0.8280\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 180/200 | Loss: 0.561995 | Acc: 0.7987 | Macro-F1: 0.7936 | Best-Acc: 0.8280\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 190/200 | Loss: 0.562569 | Acc: 0.7970 | Macro-F1: 0.7918 | Best-Acc: 0.8280\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:198: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/tmp/ipython-input-2317503036.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 200/200 | Loss: 0.561945 | Acc: 0.7967 | Macro-F1: 0.7914 | Best-Acc: 0.8280\n",
            "\n",
            "Training complete.\n",
            "Best Accuracy: 0.8280\n",
            "Classification report for best epoch:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9197    0.7195    0.8073    100156\n",
            "           1     0.7690    0.9370    0.8447     99844\n",
            "\n",
            "    accuracy                         0.8280    200000\n",
            "   macro avg     0.8443    0.8282    0.8260    200000\n",
            "weighted avg     0.8445    0.8280    0.8260    200000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import MessagePassing\n",
        "from torch_geometric.utils import softmax\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, f1_score\n",
        "\n",
        "# -------------------------\n",
        "# 1) Normalize features\n",
        "# -------------------------\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# NOTE: ensure `data` exists in your environment before running\n",
        "# normalize edge features\n",
        "edge_attr_np = data.edge_attr.cpu().numpy()\n",
        "edge_scaler = StandardScaler()\n",
        "edge_attr_np = edge_scaler.fit_transform(edge_attr_np)\n",
        "data.edge_attr = torch.tensor(edge_attr_np, dtype=torch.float, device=device)\n",
        "\n",
        "# normalize node features\n",
        "x_np = data.x.cpu().numpy()\n",
        "x_scaler = StandardScaler()\n",
        "x_np = x_scaler.fit_transform(x_np)\n",
        "data.x = torch.tensor(x_np, dtype=torch.float, device=device)\n",
        "\n",
        "# move other tensors\n",
        "data.edge_index = data.edge_index.to(device)\n",
        "data.y = data.y.to(device)\n",
        "\n",
        "# -------------------------\n",
        "# 2) Edge-aware Attention Conv\n",
        "# -------------------------\n",
        "class EdgeAttentionConv(MessagePassing):\n",
        "    \"\"\"\n",
        "    MessagePassing layer that computes attention from (src || dst || edge_attr)\n",
        "    and weights neighbor messages accordingly. Single-head.\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, out_channels, edge_dim, aggr='add'):\n",
        "        super().__init__(aggr=aggr)\n",
        "        self.lin_src = nn.Linear(in_channels, out_channels, bias=False)\n",
        "        self.lin_dst = nn.Linear(in_channels, out_channels, bias=False)  # optional\n",
        "        # attention MLP -> scalar score\n",
        "        self.att_mlp = nn.Sequential(\n",
        "            nn.Linear(out_channels * 2 + edge_dim, out_channels),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(out_channels, 1)\n",
        "        )\n",
        "        self.lin_msg = nn.Linear(in_channels, out_channels, bias=False)\n",
        "        self.lin_out = nn.Linear(out_channels, out_channels)\n",
        "        # residual projection if dims differ\n",
        "        if in_channels != out_channels:\n",
        "            self.res_proj = nn.Linear(in_channels, out_channels)\n",
        "        else:\n",
        "            self.res_proj = nn.Identity()\n",
        "\n",
        "    def forward(self, x, edge_index, edge_attr):\n",
        "        # x: [N, in_channels]\n",
        "        # edge_attr: [E, edge_dim]\n",
        "        return self.propagate(edge_index, x=x, edge_attr=edge_attr)\n",
        "\n",
        "    def message(self, x_j, x_i, edge_attr, index, ptr, size_i):\n",
        "        # x_j: source (neighbor) features [E, in_ch]\n",
        "        # x_i: target node features [E, in_ch] (if provided)\n",
        "        # Project features\n",
        "        src_proj = self.lin_src(x_j)            # [E, out]\n",
        "        dst_proj = self.lin_dst(x_i) if x_i is not None else None\n",
        "        msg_feat = self.lin_msg(x_j)            # [E, out] message content\n",
        "\n",
        "        # prepare attention input: [src_proj, dst_proj, edge_attr]\n",
        "        if dst_proj is None:\n",
        "            # fallback: use zeros for dst\n",
        "            dst_proj = torch.zeros_like(src_proj)\n",
        "        att_in = torch.cat([src_proj, dst_proj, edge_attr.to(src_proj.dtype)], dim=1)  # [E, 2*out + edge_dim]\n",
        "        att_logits = self.att_mlp(att_in).squeeze(-1)  # [E]\n",
        "\n",
        "        # normalize attention per target node\n",
        "        alpha = softmax(att_logits, index)  # [E]\n",
        "        # weight messages\n",
        "        out = msg_feat * alpha.unsqueeze(-1)  # [E, out]\n",
        "        return out\n",
        "\n",
        "    def update(self, aggr_out, x):\n",
        "        # aggr_out: [N, out]\n",
        "        out = self.lin_out(aggr_out)\n",
        "        res = self.res_proj(x)\n",
        "        return out + res\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# 3) EdgeGAT model\n",
        "# -------------------------\n",
        "class EdgeGAT(nn.Module):\n",
        "    def __init__(self, node_in_dim, edge_in_dim, hidden_dim=96, out_classes=2, dropout=0.2):\n",
        "        super().__init__()\n",
        "        self.enc1 = EdgeAttentionConv(node_in_dim, hidden_dim, edge_in_dim)\n",
        "        self.norm1 = nn.LayerNorm(hidden_dim)\n",
        "        self.drop1 = nn.Dropout(dropout)\n",
        "\n",
        "        self.enc2 = EdgeAttentionConv(hidden_dim, hidden_dim, edge_in_dim)\n",
        "        self.norm2 = nn.LayerNorm(hidden_dim)\n",
        "        self.drop2 = nn.Dropout(dropout)\n",
        "\n",
        "        self.enc3 = EdgeAttentionConv(hidden_dim, hidden_dim, edge_in_dim)\n",
        "        self.norm3 = nn.LayerNorm(hidden_dim)\n",
        "        self.drop3 = nn.Dropout(dropout)\n",
        "\n",
        "        # edge decoder: src||dst||absdiff||prod -> logits\n",
        "        dec_in = hidden_dim * 4\n",
        "        self.edge_decoder = nn.Sequential(\n",
        "            nn.Linear(dec_in, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim // 2, out_classes)\n",
        "        )\n",
        "\n",
        "    def encode_nodes(self, x, edge_index, edge_attr):\n",
        "        h = self.enc1(x, edge_index, edge_attr)\n",
        "        h = self.norm1(h)\n",
        "        h = F.gelu(h)\n",
        "        h = self.drop1(h)\n",
        "\n",
        "        h = self.enc2(h, edge_index, edge_attr)\n",
        "        h = self.norm2(h)\n",
        "        h = F.gelu(h)\n",
        "        h = self.drop2(h)\n",
        "\n",
        "        h = self.enc3(h, edge_index, edge_attr)\n",
        "        h = self.norm3(h)\n",
        "        h = F.gelu(h)\n",
        "        h = self.drop3(h)\n",
        "\n",
        "        return h\n",
        "\n",
        "    def decode_edges(self, node_emb, edge_index_batch):\n",
        "        src = node_emb[edge_index_batch[0]]   # [B, hidden]\n",
        "        dst = node_emb[edge_index_batch[1]]   # [B, hidden]\n",
        "        diff = torch.abs(src - dst)\n",
        "        prod = src * dst\n",
        "        feat = torch.cat([src, dst, diff, prod], dim=1)\n",
        "        logits = self.edge_decoder(feat)\n",
        "        return logits\n",
        "\n",
        "    def forward(self, x, edge_index, edge_attr, edge_index_for_decode=None):\n",
        "        node_emb = self.encode_nodes(x, edge_index, edge_attr)\n",
        "        if edge_index_for_decode is None:\n",
        "            edge_index_for_decode = edge_index\n",
        "        return self.decode_edges(node_emb, edge_index_for_decode), node_emb\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# 4) Training loop (AMP, cosine, clipping, batch decode)\n",
        "# -------------------------\n",
        "def train_and_evaluate_edgegat(data,\n",
        "                               hidden_dim=64,\n",
        "                               lr=5e-4,\n",
        "                               epochs=200,\n",
        "                               batch_edge_size=20000,\n",
        "                               weight_decay=1e-4):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    model = EdgeGAT(node_in_dim=data.x.shape[1],\n",
        "                    edge_in_dim=data.edge_attr.shape[1],\n",
        "                    hidden_dim=hidden_dim,\n",
        "                    out_classes=int(data.y.max().item()) + 1,\n",
        "                    dropout=0.2).to(device)\n",
        "\n",
        "    # optional compile for speed (torch>=2.0)\n",
        "    try:\n",
        "        model = torch.compile(model)\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    optimizer = torch.optim.RAdam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "    num_edges = data.edge_index.shape[1]\n",
        "    x = data.x.to(device)\n",
        "    edge_index = data.edge_index.to(device)\n",
        "    edge_attr = data.edge_attr.to(device)\n",
        "    y = data.y.to(device)\n",
        "\n",
        "    best_acc = 0.0\n",
        "    best_preds = None\n",
        "\n",
        "    print(f\"Training EdgeGAT on {device} | edges={num_edges} | nodes={x.size(0)} | classes={(y.max().item()+1)}\\n\")\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        model.train()\n",
        "        optimizer.zero_grad(set_to_none=True) # Zero gradients at the start of each epoch\n",
        "        epoch_loss = 0.0\n",
        "\n",
        "        # compute node embeddings (full graph) with autocast for speed\n",
        "        with torch.cuda.amp.autocast():\n",
        "            node_emb = model.encode_nodes(x, edge_index, edge_attr)\n",
        "\n",
        "        # decode & optimize in edge batches\n",
        "        for start in range(0, num_edges, batch_edge_size):\n",
        "            end = min(start + batch_edge_size, num_edges)\n",
        "            idx = torch.arange(start, end, device=device)\n",
        "\n",
        "            edge_batch_index = edge_index[:, idx]\n",
        "            labels_batch = y[idx]\n",
        "\n",
        "            with torch.cuda.amp.autocast():\n",
        "                logits = model.decode_edges(node_emb, edge_batch_index)\n",
        "                loss = criterion(logits, labels_batch)\n",
        "\n",
        "            # Pass retain_graph=True to keep the graph for node_emb alive\n",
        "            # as it's used across multiple backward passes in this epoch.\n",
        "            scaler.scale(loss).backward(retain_graph=True)\n",
        "            # accumulate loss for logging\n",
        "            epoch_loss += loss.item() * (end - start)\n",
        "\n",
        "        # After all batches for the epoch are processed, perform one optimization step\n",
        "        scaler.unscale_(optimizer)\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        scheduler.step()\n",
        "\n",
        "        # Evaluation (full decode)\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            full_logits, _ = model(x, edge_index, edge_attr, edge_index_for_decode=edge_index)\n",
        "            preds = full_logits.argmax(dim=1)\n",
        "            acc = (preds == y).float().mean().item()\n",
        "            macro_f1 = f1_score(y.cpu().numpy(), preds.cpu().numpy(), average='macro')\n",
        "\n",
        "        if acc > best_acc:\n",
        "            best_acc = acc\n",
        "            best_preds = preds.clone()\n",
        "\n",
        "        if epoch % 10 == 0 or epoch == 1:\n",
        "            print(f\"Epoch {epoch:03d}/{epochs} | Loss: {epoch_loss/num_edges:.6f} | Acc: {acc:.4f} | Macro-F1: {macro_f1:.4f} | Best-Acc: {best_acc:.4f}\")\n",
        "\n",
        "        if device.type == 'cuda':\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "    # final report\n",
        "    print(\"\\nTraining complete.\")\n",
        "    print(f\"Best Accuracy: {best_acc:.4f}\")\n",
        "    if best_preds is not None:\n",
        "        print(\"Classification report for best epoch:\")\n",
        "        print(classification_report(y.cpu().numpy(), best_preds.cpu().numpy(), digits=4))\n",
        "    return model, edge_scaler, x_scaler\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# 5) Run training\n",
        "# -------------------------\n",
        "trained_model, edge_scaler_out, x_scaler_out = train_and_evaluate_edgegat(\n",
        "    data,\n",
        "    hidden_dim=96,\n",
        "    lr=5e-4,\n",
        "    epochs=200,\n",
        "    batch_edge_size=20000,\n",
        "    weight_decay=1e-4\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "JoAp_lVgVV0k",
      "metadata": {
        "id": "JoAp_lVgVV0k"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, f1_score, precision_score, recall_score,\n",
        "    confusion_matrix, classification_report, roc_auc_score\n",
        ")\n",
        "\n",
        "def evaluate_edge_gnn(model, data, device=None):\n",
        "    if device is None:\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    model.eval()\n",
        "    edge_index = data.edge_index.to(device)\n",
        "    edge_attr = data.edge_attr.to(device)\n",
        "    x = data.x.to(device)\n",
        "    y = data.y.cpu().numpy()\n",
        "\n",
        "    # ---------- Forward ----------\n",
        "    with torch.no_grad(), torch.cuda.amp.autocast(enabled=(device.type == 'cuda')):\n",
        "        logits, _ = model(x, edge_index, edge_attr)\n",
        "        probs = torch.softmax(logits, dim=1).cpu().numpy()\n",
        "        preds = np.argmax(probs, axis=1)\n",
        "\n",
        "    # ---------- Basic Metrics ----------\n",
        "    acc = accuracy_score(y, preds)\n",
        "    macro_f1 = f1_score(y, preds, average='macro')\n",
        "    weighted_f1 = f1_score(y, preds, average='weighted')\n",
        "    precision_macro = precision_score(y, preds, average='macro')\n",
        "    recall_macro = recall_score(y, preds, average='macro')\n",
        "\n",
        "    print(\"====================================\")\n",
        "    print(\"          MODEL EVALUATION          \")\n",
        "    print(\"====================================\")\n",
        "    print(f\"Accuracy       : {acc:.4f}\")\n",
        "    print(f\"Macro F1       : {macro_f1:.4f}\")\n",
        "    print(f\"Weighted F1    : {weighted_f1:.4f}\")\n",
        "    print(f\"Precision      : {precision_macro:.4f}\")\n",
        "    print(f\"Recall         : {recall_macro:.4f}\")\n",
        "    print(\"------------------------------------\")\n",
        "\n",
        "    # ---------- Classification Report ----------\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(y, preds, digits=4))\n",
        "\n",
        "    # ---------- Confusion Matrix ----------\n",
        "    cm = confusion_matrix(y, preds)\n",
        "    print(\"Confusion Matrix:\\n\", cm)\n",
        "\n",
        "    # ---------- ROC-AUC ----------\n",
        "    num_classes = probs.shape[1]\n",
        "    try:\n",
        "        if num_classes == 2:\n",
        "            auc = roc_auc_score(y, probs[:, 1])\n",
        "        else:\n",
        "            auc = roc_auc_score(y, probs, multi_class=\"ovr\")\n",
        "        print(f\"\\nROC-AUC Score  : {auc:.4f}\")\n",
        "    except Exception:\n",
        "        print(\"\\nROC-AUC Score  : Not computable (labels missing)\")\n",
        "\n",
        "    print(\"====================================\")\n",
        "    return preds, probs, cm\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Q6JDwdPIRzij",
      "metadata": {
        "id": "Q6JDwdPIRzij"
      },
      "outputs": [],
      "source": [
        "def train_and_evaluate(data, lr=5e-4, epochs=300, batch_size=20000):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = EdgeGNN(\n",
        "        in_channels=data.edge_attr.shape[1],\n",
        "        hidden_channels=112,\n",
        "        out_channels=2,\n",
        "        dropout=0.4\n",
        "    ).to(device)\n",
        "\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    num_edges = data.edge_index.shape[1]\n",
        "\n",
        "    best_acc_global = 0.0           # best across all epochs\n",
        "    best_acc_last10 = 0.0           # best inside last 10 epochs window\n",
        "\n",
        "    print(f\"Training with lr={lr}, epochs={epochs} on {device}\\n\")\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "\n",
        "        model.train()\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        total_loss = 0\n",
        "\n",
        "        for start in range(0, num_edges, batch_size):\n",
        "            end = min(start + batch_size, num_edges)\n",
        "            edge_index_batch = data.edge_index[:, start:end]\n",
        "            edge_attr_batch  = data.edge_attr[start:end]\n",
        "            labels_batch     = data.y[start:end]\n",
        "\n",
        "            out = model(data.x, edge_index_batch, edge_attr_batch)\n",
        "\n",
        "            if torch.isnan(out).any():\n",
        "                print(\"⚠️ NaN detected – skipping batch\")\n",
        "                continue\n",
        "\n",
        "            loss = criterion(out, labels_batch)\n",
        "            loss.backward()\n",
        "\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "            total_loss += loss.item() * (end - start)\n",
        "\n",
        "        # -------------------------\n",
        "        # EVALUATION (entire graph)\n",
        "        # -------------------------\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            full_out = model(data.x, data.edge_index, data.edge_attr)\n",
        "            preds = full_out.argmax(dim=1)\n",
        "            acc = (preds == data.y).float().mean().item()\n",
        "\n",
        "        # update best global\n",
        "        best_acc_global = max(best_acc_global, acc)\n",
        "\n",
        "        # update best inside this 10-epoch block\n",
        "        best_acc_last10 = max(best_acc_last10, acc)\n",
        "\n",
        "        # Print every 10 epochs\n",
        "        if epoch % 10 == 0:\n",
        "            print(f\"Epoch {epoch:03d}/{epochs} | \"\n",
        "                  f\"Loss: {total_loss/num_edges:.4f} | \"\n",
        "                  f\"Acc: {acc:.4f} | \"\n",
        "                  f\"Best(Last10): {best_acc_last10:.4f} | \"\n",
        "                  f\"Best(Global): {best_acc_global:.4f}\")\n",
        "\n",
        "            best_acc_last10 = 0.0   # reset for next interval\n",
        "\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    # final report\n",
        "    print(\"\\n✅ Training Completed!\")\n",
        "    print(f\"Best Global Accuracy: {best_acc_global:.4f}\\n\")\n",
        "    print(classification_report(data.y.cpu().numpy(), preds.cpu().numpy()))\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0rc2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}